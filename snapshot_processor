#!/usr/bin/env python
import dateutil.parser
import logging
import logging.handlers

import boto3
import builtins
import copy
import cv2
import face_recognition
import netifaces
import numpy as np
import os
import pytz
import requests
import sentry_sdk
import signal
import sys
import threading
import time
import umsgpack
import zmq

from configparser import ConfigParser

from abc import abstractmethod, ABCMeta
from datetime import datetime, timedelta
from dateutil import tz
from face_recognition import face_locations, load_image_file
from http.client import BadStatusLine
from io import BytesIO
from mimetypes import MimeTypes
from pathlib import Path
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError, ApiRequestError
from googleapiclient.errors import HttpError
from requests.adapters import ConnectionError
from requests.exceptions import RequestException
from sentry_sdk import capture_exception
from socket import error as socket_error
from ssl import SSLEOFError
from threading import Thread, Lock
from time import sleep
from traceback import StackSummary
from urllib.request import pathname2url
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer

from zmq import ContextTerminated
from zmq.error import ZMQError

from PIL import Image

import botocore
import os.path
from botoflow import activity, \
    activities, \
    execute, \
    return_, \
    workflow_starter, \
    WorkflowDefinition, \
    ThreadedWorkflowExecutor, \
    ThreadedActivityExecutor
from botoflow.workers.workflow_worker import WorkflowWorker
from botoflow.workers.activity_worker import ActivityWorker
from botoflow.constants import SECONDS, MINUTES
from botoflow.exceptions import ActivityTaskFailedError, \
    WorkflowFailedError, WorkflowTimedOutError

# setup builtins used by pylib init
app_name = Path(__file__).stem
builtins.APP_NAME = app_name
builtins.SENTRY_EXTRAS = []
AWS_REGION = os.environ['AWS_DEFAULT_REGION']
class CredsConfig:
    sentry_dsn: f'opitem:"Sentry" opfield:{APP_NAME}.dsn' = None # type: ignore
    aws_akid: f'opitem:"AWS" opfield:{AWS_REGION}.akid' = None # type: ignore
    aws_sak: f'opitem:"AWS" opfield:{AWS_REGION}.sak' = None # type: ignore
# instantiate class
builtins.creds_config = CredsConfig()

from lib import app_config, \
    creds, \
    device_name, \
    device_name_base, \
    log, \
    URL_WORKER_APP, \
    URL_WORKER_PUBLISHER

from lib.bluetooth import bluetooth_init, ping_bluetooth_devices
from lib.datetime import is_list, make_timestamp, parse_datetime, ISO_DATE_FORMAT
from lib.data import make_payload
from lib.aws import boto_session, \
    swf_region, \
    swf_domain
from lib.aws.metrics import post_count_metric
from lib.aws.swf import SWFActivityWaiter, \
    swf_exception_handler, \
    SnapshotActivity, \
    DeviceInfoActivity, \
    DeviceWorkflow, \
    SnapshotWorkflow
from lib.process import SignalHandler, exec_cmd
from lib import threads
from lib.threads import thread_nanny
from lib.app import ZmqRelay, AppThread
from lib.zmq import zmq_socket, zmq_term, Closable
from lib.handler import exception_handler

URL_WORKER_FACE_DETECTOR = 'inproc://face-detector'
URL_WORKER_CLOUD_STORAGE = 'inproc://cloud-storage'

pwm_fan_control = None
pwm_fan_mutex = Lock()

HEARTBEAT_INTERVAL_SECONDS = 5

frame_server_mutex = Lock()


def wait_for_file_content(file_path):
    # FIXME: small delay to ensure that file is complete and
    # closed before attempting upload
    if os.path.exists(file_path) and os.path.isfile(file_path):
        sleep_delay = 5
        max_tries = 24
        for tries in range(1, max_tries):
            # no content
            if os.path.getsize(file_path) > 0:
                break
            # less than 5 minutes old
            if time.time() - os.path.getmtime(file_path) > 300:
                break
            log.warning('Waiting for {}s (try {} of {}) on empty file {}'.format(
                sleep_delay,
                tries,
                max_tries,
                file_path))
            sleep(sleep_delay)
            if tries >= max_tries:
                break


def create_snapshot_path(parent_path, operation, unix_timestamp, file_extension):
    return os.path.join(
        parent_path,
        "{}_".format(operation) + str(unix_timestamp) + '.' + file_extension)


def create_publisher_struct(device_key, device_label, image_data, storage_url):
    return {
        'active_devices': [
            {
                'device_key': device_key,
                'device_label': device_label,
                'type': 'camera',
                'image': image_data,
            }
        ],
        'storage_url': storage_url
    }


class CameraConfig(object):

    def __init__(self, device_key, device_label, camera_config, camera_storage=None):
        # extract connection configuration from something of this format:
        # username:password@ip:port,rtsp_port
        camera_auth, camera_url = camera_config.split('@')
        if ':' not in camera_auth or ':' not in camera_url:
            raise AssertionError("Camera parameters missing for '{}.'".format(device_key))
        # split the rtsp port number
        camera_url_parts = camera_url.split(',')
        if len(camera_url_parts) == 1:
            camera_url = camera_url_parts[0]
            rtsp_port = camera_url.split(':')[1]
        elif len(camera_url_parts) == 2:
            camera_url, rtsp_port = camera_url_parts
        # set locals
        self._name = device_key
        self._device_key = device_key
        self._device_label = device_label
        self._basic_auth = camera_auth
        self._username, self._password = camera_auth.split(':')
        self._url = camera_url
        self._ip, self._port = camera_url.split(':')
        self._rtsp_port = rtsp_port
        self._camera_storage = camera_storage

    def __str__(self) -> str:
        return self._url

    @property
    def name(self):
        return self._name

    @property
    def device_key(self):
        return self._device_key

    @property
    def device_label(self):
        return self._device_label

    @property
    def basic_auth(self):
        return self._basic_auth

    @property
    def username(self):
        return self._username

    @property
    def password(self):
        return self._password

    @property
    def url(self):
        return self._url

    @property
    def ip(self):
        return self._ip

    @property
    def port(self):
        return self._port

    @property
    def rtsp_port(self):
        return self.rtsp_port

    @property
    def camera_storage(self):
        return self._camera_storage


class FileType(object):

    def __init__(self):
        self.mime = MimeTypes()

    def mime_type(self, file_path):
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None and len(mime_type) > 0:
            return mime_type[0]
        return None

    def test_type(self, file_path, file_type):
        mime_type = self.mime_type(file_path)
        if mime_type is not None and mime_type.startswith('{}/'.format(file_type)):
            # return the specific file type
            return mime_type.split('/')[1]
        return None


filetype = None


class Snapshot(ZmqRelay):

    def __init__(self, camera_profiles, cloud_storage_url):
        ZmqRelay.__init__(self,
            name=self.__class__.__name__,
            source_zmq_url=URL_WORKER_APP,
            source_socket_type=zmq.PULL,
            sink_zmq_url=URL_WORKER_PUBLISHER,
            sink_socket_type=zmq.PUSH)

        self.cameras = camera_profiles
        self.default_command = app_config.get('camera', 'default_command')
        self.default_image_format = app_config.get('camera', 'default_image_format')

        self.cloud_storage_url = cloud_storage_url

        self.face_detector_socket = None
        if app_config.getboolean('snapshots', 'face_detection_enabled'):
            self.face_detector_socket = self.get_socket(zmq.PUSH)
        self.capture_threads = {}

    def startup(self):
        if self.face_detector_socket:
            self.face_detector_socket.connect(URL_WORKER_FACE_DETECTOR)

    def process_message(self, zmq_socket):
        output_trigger = zmq_socket.recv_pyobj()
        # FIXME: remove block
        if isinstance(output_trigger, dict):
            timestamp = output_trigger['timestamp']
            device_key = output_trigger['device_key']
            device_label = output_trigger['device_label']
            if 'device_params' in output_trigger:
                camera_config_string = output_trigger['device_params']
        elif isinstance(output_trigger, tuple):
            #FIXME
            if len(output_trigger) > 3:
                log.warn('Discarding unknown trigger type {}'.format(type(output_trigger)))
                return
            timestamp = make_timestamp()
            device_key, device_label, camera_config_string = output_trigger
        else:
            log.warn('Discarding unknown trigger type {}'.format(type(output_trigger)))
            return
        if device_key not in self.cameras:
            log.error("Camera configuration missing for '{}.'".format(device_label))
            post_count_metric('Errors')
            return
        try:
            camera_config = CameraConfig(
                device_key=device_key,
                device_label=device_label,
                camera_config=camera_config_string,
                camera_storage=self.cameras[device_key]['storage'])
        except AssertionError:
            post_count_metric('Errors')
            return
        image_data = None
        # grab a first frame for overall context
        for tries in range(1, 4):
            try:
                r = requests.get('http://{}/cgi-bin/CGIProxy.fcgi'.format(camera_config.url), params={
                    'cmd': self.default_command,
                    'usr': camera_config.username,
                    'pwd': camera_config.password,
                })
                image_data = r.content
                im = Image.open(BytesIO(image_data))
                break
            except (OSError, ConnectionError, RequestException) as e:
                log.warning("Problem getting image from {}. Retrying...".format(camera_config),
                            exc_info=1)
                sleep(0.1)
                if tries >= 3:
                    log.error("Giving up getting image from {} after {} tries: {}".format(
                        camera_config,
                        tries,
                        repr(e)))
                    post_count_metric('Errors')
                    break
        # construct message to publish
        unix_timestamp = int((timestamp.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds())
        log.debug('Basing {} off of {}'.format(unix_timestamp, timestamp))
        # publisher data
        publisher_data = create_publisher_struct(
            device_key=device_key,
            device_label=device_label,
            image_data=image_data,
            storage_url=self.cloud_storage_url)
        # look for faces in a continuous stream
        if app_config.getboolean('camera', 'rtsp_capture_enabled'):
            capture_thread = None
            if device_key in self.capture_threads:
                capture_thread = self.capture_threads[device_key]
            if capture_thread and capture_thread.is_alive():
                log.info('Not starting additional capture thread for {} which is still alive.'.format(device_key))
            else:
                capture_thread = FrameServer(
                    camera_config=camera_config,
                    snapshot_timestamp=unix_timestamp,
                    publisher_data=publisher_data)
                # replace the existing thread
                self.capture_threads[device_key] = capture_thread
                # start the thread
                capture_thread.start()
        elif self.face_detector_socket:
            # send image data for processing
            self.face_detector_socket.send_pyobj((
                None,
                camera_config.camera_storage,
                unix_timestamp,
                publisher_data
            ))
        # publish event data
        self.socket.send_pyobj(publisher_data)
        # create output file path
        output_filename = create_snapshot_path(
            parent_path=camera_config.camera_storage,
            operation='fetch',
            unix_timestamp=unix_timestamp,
            file_extension=self.default_image_format)
        log.info('{} ({} {} {}) => {}.'.format(device_label, im.format, im.size, im.mode, output_filename))
        # persist for Cloud
        im.save(output_filename)


class DeviceEvent(object):

    def __init__(self, device_key, device_type, device_location=None):
        self._device_key = device_key
        self._device_type = device_type
        self._device_location = device_location

        self._timestamp = None
        self._event_detail = None

    @property
    def device_key(self):
        return self._device_key

    @property
    def device_type(self):
        return self._device_type

    @property
    def device_location(self):
        return self._device_location

    @property
    def timestamp(self):
        if self._timestamp is None:
            self._timestamp = make_timestamp()
        return self._timestamp

    @timestamp.setter
    def timestamp(self, value):
        self._timestamp = make_timestamp(timestamp=value)

    @property
    def timestamp_string(self):
        return self.timestamp.strftime(ISO_DATE_FORMAT)

    @property
    def event_detail(self):
        return self._event_detail

    @event_detail.setter
    def event_detail(self, value):
        self._event_detail = value

    @property
    def dict(self):
        representation = {
            'device_key': self._device_key,
            'device_type': self._device_type,
            'timestamp': self.timestamp_string
        }
        if self._device_location:
            representation.update({
                'device_location': self._device_location
            })
        if self._event_detail:
            representation.update({
                'event_detail': self._event_detail
            })
        return representation

    def __str__(self):
        return self._device_key


class CloudStorage(object, metaclass=ABCMeta):
    @abstractmethod
    def cloud_storage_url(self):
        return NotImplemented


class GoogleDriveManager(CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        # set by the thread
        self._gdrive_folder_id = None
        self._gdrive_folder_url = None

    @property
    def cloud_storage_folder_id(self):
        return self._gdrive_folder_id

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug('Google credentials not found in [{}]. Interactive setup may follow.'.format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug('Saved Google credentials to {}'.format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(app_name), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError('Unexpected result listing Google Drive for {}: {}'.format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link


class GoogleDriveArchiver(AppThread, GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder, gdrive_folder_id, gdrive_folder_url):
        AppThread.__init__(self, name=self.__class__.__name__)
        GoogleDriveManager.__init__(self,
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)

        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = dict()

        self._gdrive_folder_id = gdrive_folder_id
        self._gdrive_folder_url = gdrive_folder_url

    def run(self):
        while not threads.shutting_down:
            log.debug('Finding files in {} ({}) to archive.'.format(self._gdrive_folder, self._gdrive_folder_id))
            try:
                file_list = self._archive_drive.ListFile({
                    'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                        self._gdrive_folder_id
                    ),
                    'maxResults': 100,
                })
                archived = 0
                try:
                    while True:
                        page = file_list.GetList()
                        log.info('Inspecting {} files for archival...'.format(len(page)))
                        for file1 in page:
                            if self.archive(gdrive=self._archive_drive,
                                            gdrive_file=file1,
                                            root_folder_id=self._gdrive_folder_id):
                                archived += 1
                except StopIteration:
                    log.info('Archived {} image snapshots.'.format(archived))
            except (ApiRequestError, FileNotUploadedError, socket_error, HttpError):
                log.exception('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            threads.interruptable_sleep.wait(60*60*24)

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, _ = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, _ = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, _ = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = list()
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False


class GoogleDriveUploader(AppThread, Closable, GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder):
        AppThread.__init__(self, name=self.__class__.__name__)
        Closable.__init__(self, connect_url=URL_WORKER_CLOUD_STORAGE, socket_type=zmq.PULL)
        GoogleDriveManager.__init__(self,
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)

        # determine the Drive folder details synchronously
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, self._gdrive_folder)

    def run(self):
        with exception_handler(closable=self):
            while not threads.shutting_down:
                (snapshot_path, snapshot_timestamp) = self.socket.recv_pyobj()
                #FIXME: remove
                wait_for_file_content(snapshot_path)
                self.upload(file_path=snapshot_path, created_time=snapshot_timestamp)

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = filetype.mime_type(file_path)
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            for i in range(0, 3):
                try:
                    f.Upload()
                except (ApiRequestError, BadStatusLine, SSLEOFError, BrokenPipeError):
                    if i >= 3:
                        raise
                    else:
                        log.warning("Problem uploading '{}' to Google Drive. Retrying...".format(file_path), exc_info=1)
                        sleep(1)
                        continue
                break
            link_msg = ""
            if 'thumbnailLink'in f:
                link = f['thumbnailLink']
                # specify our own thumbnail size
                if '=' in link:
                    link = link.rsplit('=')[0]
                    link += '=s1024'
                link_msg = " Thumbnail at {}".format(link)
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}').{}".format(
                    os.path.basename(file_path), self._gdrive_folder, f['id'], link_msg))
        except FileNotUploadedError:
            log.exception('Cannot upload {} to Google Drive'.format(file_path))


class UploadEventHandler(FileSystemEventHandler, Closable):

    def __init__(self, fs_observer, snapshot_root):
        FileSystemEventHandler.__init__(self)
        Closable.__init__(self, connect_url=URL_WORKER_PUBLISHER, socket_type=zmq.PUSH)

        self.last_modified = None
        self.device_events = dict()
        self._snapshot_root = snapshot_root

        fs_observer.schedule(self, self._snapshot_root, recursive=True)

        self.cloud_storage_socket = self.get_socket(zmq.PUSH)
        self.cloud_storage_socket.connect(URL_WORKER_CLOUD_STORAGE)

        self.face_detector_socket = None
        if app_config.getboolean('snapshots', 'face_detection_enabled'):
            self.face_detector_socket = self.get_socket(zmq.PUSH)
            self.face_detector_socket.connect(URL_WORKER_FACE_DETECTOR)

        self._cloud_storage_url = None

    @property
    def cloud_storage_url(self):
        return self._cloud_storage_url

    @cloud_storage_url.setter
    def cloud_storage_url(self, cloud_storage_url):
        self._cloud_storage_url = cloud_storage_url

    def add_image_dir(self, device_key, device_type, device_location, image_dir):
        if image_dir in self.device_events:
            raise RuntimeError('Image source label {} is already configured.'.format(device_location))
        # create pre-canned device events for reuse later
        self.device_events[image_dir] = DeviceEvent(
            device_key=device_key,
            device_type=device_type,
            device_location=device_location
        )

    def _get_device_event(self, event_directory):
        for image_dir, device_event in list(self.device_events.items()):
            if image_dir in event_directory:
                return copy.copy(device_event)
        return None

    @property
    def watched_dirs(self):
        return list(self.device_events.keys())

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(self._snapshot_root):
                # noinspection PyBroadException
                try:
                    # image snapshot that can be mapped to a device?
                    device_event = self._get_device_event(snapshot_path)
                    if device_event:
                        log.info('{} from {}'.format(device_event, snapshot_path))
                        file_base_name = os.path.splitext(os.path.basename(snapshot_path))[0]
                        if '_' in file_base_name:
                            date_string = ' '.join(file_base_name.split('_')[1:])
                        else:
                            date_string = file_base_name
                        device_event.timestamp = date_string
                        with exception_handler(closable=self, and_raise=False, close_on_exit=False):
                            # do not notify for fetched image data
                            if 'fetch' not in snapshot_path:
                                self.socket.send_pyobj({
                                    'active_devices': [device_event.dict],
                                    'storage_url': self._cloud_storage_url
                                })
                                if self.face_detector_socket:
                                    # start processing the image data
                                    if file_base_name.endswith('.jpg') and 'face' not in snapshot_path:
                                        self.face_detector_socket.send_pyobj((
                                            snapshot_path,
                                            # no parent path, extracted from snapshot_path
                                            None,
                                            device_event.timestamp,
                                            # no image data
                                            None
                                        ))
                            # upload the image snapshot to Cloud
                            self.cloud_storage_socket.send_pyobj((
                                snapshot_path,
                                device_event.timestamp
                            ))
                    else:
                        log.warning("Ignored unmapped path event: {}".format(snapshot_path))
                except Exception:
                    log.exception('Cannot process {}'.format(snapshot_path))
                    capture_exception()
                    sleep(1)


class FacePuller(ZmqRelay):

    def __init__(self, camera_profiles, cloud_storage_url, source_zmq_url):
        ZmqRelay.__init__(self,
            name=self.__class__.__name__,
            source_zmq_url=source_zmq_url,
            source_socket_type=zmq.PULL,
            sink_zmq_url=URL_WORKER_PUBLISHER,
            sink_socket_type=zmq.PUSH)
        self.cameras = camera_profiles
        self.cloud_storage_url = cloud_storage_url

    def process_message(self, zmq_socket):
        # extract image data
        md = zmq_socket.recv_json()
        msg = zmq_socket.recv()
        buf = memoryview(msg)
        arr = np.frombuffer(buf, dtype=md['dtype'])
        numpy_array=arr.reshape(md['shape'])
        # extract metadata
        device_key = md['device_key']
        device_label = md['device_label']
        face_num = md['face_num']
        # storage configuration
        parent_path = self.cameras[device_key]['storage']
        timestamp = make_timestamp()
        unix_timestamp = int((timestamp.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds())
        # create PIL Image object
        pil_image = Image.fromarray(numpy_array)
        # save the additional image data
        face_snapshot_path = create_snapshot_path(
            parent_path=parent_path,
            operation="face{}".format(face_num),
            unix_timestamp=unix_timestamp,
            file_extension='jpg')
        log.info("Saving face #{} from {} to {}".format(face_num, device_key, face_snapshot_path))
        pil_image.save(face_snapshot_path)
        # publish this as an event
        image_output = BytesIO()
        pil_image.save(image_output, format='JPEG')
        publisher_data = create_publisher_struct(
            device_key=device_key,
            device_label=device_label,
            image_data=image_output.getvalue(),
            storage_url=self.cloud_storage_url)
        self.socket.send_pyobj(publisher_data)


class FaceDetector(ZmqRelay):

    def __init__(self):
        ZmqRelay.__init__(self,
            name=self.__class__.__name__,
            source_zmq_url=URL_WORKER_FACE_DETECTOR,
            source_socket_type=zmq.PULL,
            sink_zmq_url=URL_WORKER_PUBLISHER,
            sink_socket_type=zmq.PUSH)

    def process_message(self, zmq_socket):
        active_device = None
        (snapshot_path, parent_path, snapshot_timestamp, publisher_data) = self.socket.recv_pyobj()
        if snapshot_path is not None:
            wait_for_file_content(snapshot_path)
            (parent_path, snapshot_file) = os.path.split(snapshot_path)
            # process file data
            log.debug("Loading image data from {}".format(snapshot_file))
            image = load_image_file(snapshot_path)
            log.debug("Finding faces in image file {}".format(snapshot_path))
        elif publisher_data is not None:
            active_device = publisher_data['active_devices'][0]
            log.debug("Loading image data from {} event.".format(active_device['device_label']))
            if 'cv2_frame' in active_device:
                image = active_device['cv2_frame']
            else:
                pil_image = Image.open(BytesIO(active_device['image']))
                log.debug("Finding faces in image {} {} {}...".format(pil_image.format, pil_image.size, pil_image.mode))
                image = np.array(pil_image)
        else:
            raise ValueError("No viable image data to use.")
        # start some cooling
        if pwm_fan_control:
            pwm_fan_control.start_fan()
        # find faces using the specified model
        faces = face_locations(
            image,
            number_of_times_to_upsample=0,
            model=app_config.get('snapshots', 'face_detection_model'))
        if (len(faces) > 0):
            log.info("{} faces detected.".format(len(faces)))
        else:
            log.debug("{} faces detected.".format(len(faces)))
        face_num = 1
        for face_location in faces:
            top, right, bottom, left = face_location
            log.info("Extracting face #{} at Top: {}, Left: {}, Bottom: {}, Right: {}".format(
                face_num,
                top,
                left,
                bottom,
                right))
            # extract sub-image data aligned to face
            face_image = image[top:bottom, left:right]
            pil_image = Image.fromarray(face_image)
            if active_device is not None:
                image_output = BytesIO()
                pil_image.save(image_output, format='JPEG')
                active_device['image'] = image_output.getvalue()
                # remove any numpy data
                if 'cv2_frame' in active_device:
                    del active_device['cv2_frame']
                zmq_socket.send_pyobj(publisher_data)
            # save the additional image data
            face_snapshot_path = create_snapshot_path(
                parent_path=parent_path,
                operation="face{}".format(face_num),
                unix_timestamp=snapshot_timestamp,
                file_extension='jpg')
            log.info("Saving face #{} to {}".format(face_num, face_snapshot_path))
            pil_image.save(face_snapshot_path)
            # next face
            face_num += 1


class FrameServer(AppThread, Closable):

    def __init__(self, camera_config, snapshot_timestamp, publisher_data):
        AppThread.__init__(self, self.__class__.__name__)
        Closable.__init__(self, connect_url=URL_WORKER_FACE_DETECTOR, socket_type=zmq.PUSH)

        self.capture_duration_seconds = app_config.getint('camera', 'rtsp_capture_duration_seconds')
        self.rtsp_url = 'rtsp://{}@{}/{}'.format(
            camera_config.basic_auth,
            camera_config.url,
            app_config.get('camera', 'rtsp_path'))
        self.camera_name = camera_config.name
        self.camera_address = camera_config.url
        # to send to face detector
        self.parent_path = camera_config.camera_storage
        self.snapshot_timestamp = snapshot_timestamp
        self.publisher_data = publisher_data

    def run(self):
        global frame_server_mutex
        frame_count = 0
        capture = None
        with exception_handler(closable=self):
            try:
                log.info('Waiting for air time with {}...'.format(self.camera_name))
                frame_server_mutex.acquire()
                log.info('Starting video capture from {}@{}...'.format(self.camera_name, self.camera_address))
                #TODO: https://github.com/ageitgey/face_recognition/issues/659#issuecomment-468008178
                capture = cv2.VideoCapture(self.rtsp_url)
                log.info('Fetching frames from {}@{} for {} seconds.'.format(self.camera_name, self.camera_address, self.capture_duration_seconds))
                start_time = time.time()
                #TODO: adjust based on time for first frame
                while capture and capture.isOpened() and time.time() - start_time <= self.capture_duration_seconds:
                    ret, frame = capture.read()
                    if not ret:
                        log.warn('No more frames from {}@{} after {} frames.'.format(self.camera_name, self.camera_address, frame_count))
                        break
                    if frame is None:
                        sleep(0.01)
                        continue
                    frame_count += 1
                    active_device = self.publisher_data['active_devices'][0]
                    active_device['cv2_frame'] = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    self.socket.send_pyobj((
                        None,
                        self.parent_path,
                        self.snapshot_timestamp,
                        self.publisher_data
                    ))
                    # do not consume faster than this rate
                    sleep(0.01)
                    #FIXME: take only a few frames for test
                    if frame_count >= 10:
                        break
            finally:
                if capture:
                    capture.release()
                frame_server_mutex.release()
            log.info('Read {} frames from {}@{} in {}s.'.format(
                frame_count,
                self.camera_name,
                self.camera_address,
                time.time() - start_time))


class PwmFanControl(AppThread):

    def __init__(self, pwm_device_path_prefix, pwm_decrement_rate=1):
        AppThread.__init__(self, name=self.__class__.__name__)

        self.rpm_measured_file = os.path.join(pwm_device_path_prefix, 'rpm_measured')
        self.target_pwm = os.path.join(pwm_device_path_prefix, 'target_pwm')
        self.pwm_decrement_rate = pwm_decrement_rate
        self.pwm_cap = 255
        pwm_cap_file = os.path.join(pwm_device_path_prefix, 'pwm_cap')
        if os.path.exists(pwm_cap_file):
            with open(pwm_cap_file) as f:
                self.pwm_cap = int(f.read())

    def _read(self, file_name):
        with open(file_name) as f:
            return int(f.read())

    def _write(self, file_name, value):
        global pwm_fan_mutex
        try:
            pwm_fan_mutex.acquire()
            with open(file_name, 'w') as f:
                f.write(str(value))
        finally:
            pwm_fan_mutex.release()

    def start_fan(self):
        self._write(self.target_pwm, self.pwm_cap)

    def stop_fan(self):
        self._write(self.target_pwm, 0)

    def read_fan_state(self, detail=False):
        pwm_value = self._read(self.target_pwm)
        summary = None
        if detail:
            rpm_value = self._read(self.rpm_measured_file)
            summary = 'Fan is {} RPM (PWM={})'.format(rpm_value, pwm_value)
        return pwm_value, summary

    # noinspection PyBroadException
    def run(self):
        pwm_value, summary = self.read_fan_state(detail=True)
        log.info(summary)
        while not threads.shutting_down:
            with exception_handler():
                # read the fan value and only tick down if it is above 0
                pwm_value, _ = self.read_fan_state()
                if pwm_value > 0:
                    # decrement at required reate
                    pwm_value -= self.pwm_decrement_rate
                    if pwm_value < 0:
                        pwm_value = 0
                    # write the new value
                    self._write(self.target_pwm, pwm_value)
                    # short sleep, and re-check
                    sleep(1)
                    continue
                threads.interruptable_sleep.wait(HEARTBEAT_INTERVAL_SECONDS)
        # stop the fan for shutdown
        self.stop_fan()
        pwm_value, summary = self.read_fan_state(detail=True)
        log.info(summary)


if __name__ == "__main__":
    # set up fan control
    pwm_device_path_prefix = '/sys/devices/pwm-fan'
    if os.path.exists(os.path.join(pwm_device_path_prefix, 'target_pwm')):
        pwm_fan_control = PwmFanControl(pwm_device_path_prefix)
    # connect to SWF
    swf_activity = SnapshotActivity(URL_WORKER_APP)
    swf_worker = ThreadedActivityExecutor(ActivityWorker(boto_session,
                                            swf_region,
                                            swf_domain,
                                            app_name,
                                            swf_activity, DeviceInfoActivity()))
    swf_worker._worker.unhandled_exception_handler = swf_exception_handler
    swf_worker.start()
    # file system listener
    observer = Observer()
    observer.name = observer.__class__.__name__
    snapshot_root = app_config.get('snapshots', 'root_dir')
    upload_event_handler = UploadEventHandler(snapshot_root=snapshot_root, fs_observer=observer)
    # construct the device representation
    input_types = dict(app_config.items('input_type'))
    input_locations = dict(app_config.items('input_location'))
    output_types = dict(app_config.items('output_type'))
    output_locations = dict(app_config.items('output_location'))
    device_info = dict()
    device_info['inputs'] = list()
    for field, input_type in list(input_types.items()):
        input_location = input_locations[field]
        device_key = '{} {}'.format(input_locations[field], input_type)
        device_info['inputs'].append({
            'type': input_type,
            'location': input_location,
            'device_key': device_key
        })
        if input_type.lower() == 'camera':
            upload_event_handler.add_image_dir(
                device_key=device_key,
                device_type=input_type,
                device_location=input_location,
                image_dir=os.path.join(
                    app_config.get('snapshots', 'upload_dir'),
                    input_location.lower().replace(' ', '')))
    device_info['outputs'] = list()
    camera_profiles = {}
    for field, output_type in list(output_types.items()):
        output_device = {}
        if field in output_locations:
            output_location = output_locations[field]
            device_key = '{} {}'.format(output_location, output_type)
            output_device['location'] = output_location
        else:
            device_key = output_type
        output_device.update({
            'type': output_type,
            'device_key': device_key
        })
        device_info['outputs'].append(output_device)
        if output_type.lower() == 'camera':
            # now build the profile for internal use
            camera_profile = output_device.copy()
            camera_profile.update({
                'storage': os.path.join(
                    snapshot_root, 
                    app_config.get('snapshots', 'upload_dir'), 
                    output_location.lower().replace(' ', ''))
            })
            camera_profiles[device_key] = camera_profile
    log.info('Monitoring directories in {} for changes: {}'.format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # face detection
    if app_config.getboolean('snapshots', 'face_detection_enabled'):
        face_detector = FaceDetector()
    else:
        face_detector = None
    # top-level types
    filetype = FileType()
    # ensure that auth is properly set up first
    try:
        google_drive_uploader = GoogleDriveUploader(
            gauth_creds_file=app_config.get('gdrive', 'creds_file'),
            gdrive_folder=app_config.get('gdrive', 'folder'))
        google_drive_archiver = GoogleDriveArchiver(
            gauth_creds_file=app_config.get('gdrive', 'creds_file'),
            gdrive_folder=app_config.get('gdrive', 'folder'),
            gdrive_folder_id=google_drive_uploader.cloud_storage_folder_id,
            gdrive_folder_url=google_drive_uploader.cloud_storage_url)
    except Exception:
        log.fatal('Google Drive setup failure.', exc_info=1)
        exit(1)
    # tell the uploader about the Cloud storage URL
    upload_event_handler.cloud_storage_url = google_drive_uploader.cloud_storage_url
    snapshotter = Snapshot(camera_profiles=camera_profiles, cloud_storage_url=google_drive_uploader.cloud_storage_url)
    # start threads
    snapshotter.start()
    # ZMQ endpoints
    pub_ip=app_config.get('app', 'eth0_ip')
    pub_port=app_config.get('zmq', 'pubsub_port')
    publisher = ZmqRelay(
        name='heartbeat',
        source_zmq_url=URL_WORKER_PUBLISHER,
        source_socket_type=zmq.PULL,
        sink_zmq_url=f'tcp://{pub_ip}:{pub_port}',
        sink_socket_type=zmq.PUB)
    publisher.start()
    # start external PULL socket
    push_ip=app_config.get('app', 'eth0_ip')
    push_port=app_config.get('zmq', 'pushpull_port')
    puller = FacePuller(
        camera_profiles=camera_profiles,
        cloud_storage_url=google_drive_uploader.cloud_storage_url,
        source_zmq_url=f'tcp://{push_ip}:{push_port}')
    puller.start()
    # start the collectors
    observer.start()
    threads.threads_tracked.add(observer.getName())
    # must be main thread
    signal_handler = SignalHandler()
    publisher_socket = zmq_socket(zmq.PUSH)
    try:
        # startup completed
        # back to INFO logging
        log.setLevel(logging.INFO)
        if pwm_fan_control:
            pwm_fan_control.start()
        if face_detector:
            face_detector.start()
        # start Google Drive uploader
        google_drive_uploader.start()
        # start the Google Driver archiver last
        google_drive_archiver.start()
        # start thread nanny
        nanny = threading.Thread(name='nanny', target=thread_nanny, args=(signal_handler,))
        nanny.setDaemon(True)
        nanny.start()
        # start heartbeat loop
        publisher_socket.connect(URL_WORKER_PUBLISHER)
        while not threads.shutting_down:
            publisher_socket.send_pyobj({
                #TODO statistics
                'device_info': device_info
            })
            threads.interruptable_sleep.wait(HEARTBEAT_INTERVAL_SECONDS)
        raise RuntimeWarning("Shutting down...")
    except(KeyboardInterrupt, RuntimeWarning, ContextTerminated) as e:
        log.warning(str(e))
        threads.shutting_down = True
        threads.interruptable_sleep.set()
        message = "Shutting down {}..."
        log.info(message.format('SWF activity worker'))
        swf_worker.stop()
        log.info(message.format('Application threads'))
        observer.stop()
        observer.join()
        upload_event_handler.close()
        # since this thread and the signal handler are one and the same
        publisher_socket.close()
        zmq_term()
        log.info(message.format('SWF worker'))
        swf_worker.join()
        log.info('Shutdown complete.')