#!/usr/bin/env python
import dateutil.parser
import hashlib
import logging
import logging.handlers

import copy
import json
import os
import pytz
import requests
import signal
import sys
import threading
import time
import umsgpack
import zmq

from fcntl import fcntl, F_GETFL, F_SETFL
from os import O_NONBLOCK, read

from configparser import ConfigParser

from abc import abstractmethod, ABCMeta
from datetime import datetime, timedelta
from dateutil import tz
from http.client import BadStatusLine
from io import BytesIO
from mimetypes import MimeTypes
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError, ApiRequestError
from googleapiclient.errors import HttpError
from raven import Client as Sentry
from socket import error as socket_error
from ssl import SSLEOFError
from subprocess import PIPE, Popen
from threading import Thread
from time import sleep
from urllib.request import pathname2url
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer

from watson_developer_cloud import TextToSpeechV1
from watson_developer_cloud import WatsonApiException

from zmq import ContextTerminated
from zmq.error import ZMQError

from PIL import Image

APP = os.path.basename(__file__)
DIR = os.path.abspath(os.path.dirname(__file__))
# PID file check
pidfile = '/var/run/{}.pid'.format(APP)
mypid = os.getpid()
if os.path.isfile(pidfile):
    pid = None
    try:
        pid = int(open(pidfile, 'r').read())
    except ValueError:
        print('{} contains no valid PID, updating with {}'.format(pidfile, mypid))
    if pid is not None:
        message = '{} exists for PID {}.'.format(pidfile, pid)
        proc_path = '/proc/{}/cmdline'.format(pid)
        # existing process?
        if os.path.isfile(proc_path):
            proc_info = open(proc_path, 'r').read()
            # there is an existing process and may be this program
            if proc_info is not None and 'python' in proc_info and APP in proc_info and mypid != pid:
                print('{} is already running. {}'.format(APP, message))
                sys.exit(1)
# take control of PID file
open(pidfile, 'w').write(str(mypid))

TTS_DIR = '/data/tts_samples'
# set the working directory for libraries that assume this (such as PyDrive)
os.chdir(DIR)
log = logging.getLogger(APP)
# do not propagate to console logging
log.propagate = False

config = ConfigParser()
config.optionxform = str
config.read([os.path.join(DIR, '{}.conf'.format(APP))])

snapshot_root = config.get('snapshots', 'root_dir')

cloud_storage = None

zmq_context = zmq.Context()
zmq_context.setsockopt(zmq.LINGER, 0)

URL_WORKER_NOTIFIER = 'inproc://notifier'
URL_WORKER_SNAPSHOT = 'inproc://snapshot'
URL_WORKER_UPLOADER = 'inproc://uploader'
URL_WORKER_CLOUD_STORAGE = 'inproc://cloud-storage'
DATE_FORMAT = '%Y-%m-%dT%H:%M:%S.%f%z'

HEARTBEAT_INTERVAL_SECONDS = 5

sentry = Sentry()

# lifted from the defunct https://github.com/baudm/mplayer.py/blob/master/mplayer/core.py
mplayer = ['mplayer',
           '-slave',
           '-idle',
           '-really-quiet',
           '-nolirc',
           '-msglevel', 'global=4',
           '-input', 'nodefault-bindings',
           '-noconfig', 'all']


def make_timestamp(timestamp=None, as_tz=pytz.utc, make_string=False):
    if timestamp is None:
        timestamp = datetime.utcnow().replace(tzinfo=pytz.utc)
    elif isinstance(timestamp, float) or isinstance(timestamp, int):
        timestamp = datetime.utcfromtimestamp(timestamp).replace(tzinfo=pytz.utc)
    elif isinstance(timestamp, str):
        try:
            timestamp = dateutil.parser.parse(timestamp)
            log.debug('Parsed timestamp is {}'.format(timestamp))
        except ValueError:
            try:
                timestamp = datetime.utcfromtimestamp(int(timestamp)).replace(tzinfo=pytz.utc)
                log.debug('Parsed integer timestamp is {}'.format(timestamp))
            except ValueError:
                raise RuntimeError("Unknown date/time type: '{}'".format(timestamp))
    if timestamp.tzinfo is None:
        local_tz = tz.tzlocal()
        #TODO: fixme
        log.info('{}: fixed to local time {}'.format(timestamp, local_tz))
        # we use the default specific to the physical locality of the devices
        timestamp = timestamp.replace(tzinfo=local_tz)
    if timestamp.tzinfo != as_tz:
        # now adjust to requested TZ
        new_timestamp = timestamp.astimezone(tz=as_tz)
        #TODO: fixme
        log.info('{} adjusted to {} ({} to {})'.format(timestamp, new_timestamp, timestamp.tzinfo, as_tz))
        timestamp = new_timestamp
    if make_string:
        return timestamp.strftime(DATE_FORMAT)
    return timestamp


class Uploader(Thread):

    def __init__(self):
        super(Uploader, self).__init__(name=self.__class__.__name__)
        self.daemon = True
        # inproc socket to accept messages to publish
        # to the outside world
        self.inproc_pull = zmq_context.socket(zmq.PULL)
        self.inproc_pull.bind(URL_WORKER_UPLOADER)

    def run(self):
        # Socket to talk to the outside world
        publisher = zmq_context.socket(zmq.PUB)
        try:
            publisher.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                      port=config.get('zmq', 'pubsub_port')))
        except ZMQError:
            log.exception(self.__class__.__name__)
            sentry.captureException()
            raise

        while True:
            try:
                (timestamp, event_data) = self.inproc_pull.recv_pyobj()
                publisher.send(Uploader.make_payload(timestamp, event_data))
            except ContextTerminated:
                self.inproc_pull.close()
                publisher.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    @staticmethod
    def make_payload(timestamp=None, data=None):
        send_timestamp = make_timestamp(timestamp=timestamp, make_string=True)
        log.debug('Payload timestamp {}'.format(send_timestamp))
        payload = {'timestamp': send_timestamp}
        if data is not None and len(data) > 0:
            payload['data'] = data
        #TODO: fix me for small payloads
        #log.debug(json.dumps(payload))
        return umsgpack.packb(payload)


class DeviceActivator(Thread):

    def __init__(self):
        super(DeviceActivator, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.listener = zmq_context.socket(zmq.PULL)
        # what to do with notifications
        self.notifier = zmq_context.socket(zmq.PUSH)
        # to create snapshots
        self.snapshot = zmq_context.socket(zmq.PUSH)

    def run(self):
        # outputs
        self.notifier.connect(URL_WORKER_NOTIFIER)
        self.snapshot.connect(URL_WORKER_SNAPSHOT)

        # Socket to talk to the outside world
        try:
            self.listener.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                          port=config.get('zmq', 'pushpull_port')))
        except ZMQError:
            log.exception(self.__class__.__name__)
            sentry.captureException()
            raise

        while True:
            try:
                event = umsgpack.unpackb(self.listener.recv())
                if 'timestamp' in event:
                    #TODO: fixme
                    log.info('DEBUG: received timestamp {}'.format(event['timestamp']))
                    timestamp = make_timestamp(timestamp=event['timestamp'], as_tz=tz.tzlocal())
                    # TODO: fixme
                    log.info('DEBUG: transmuted timestamp to {}'.format(timestamp))
                else:
                    timestamp = make_timestamp(as_tz=tz.tzlocal())
                if 'data' not in event:
                    log.warning('Unknown event data: {}'.format(event))
                    continue
                event_data = event['data']
                if 'trigger_output' in event_data:
                    trigger_output = event_data['trigger_output']
                    output_type = trigger_output['type']
                    if output_type.lower() == 'tts':
                        if 'input_context' not in event_data:
                            log.warning('{} requested without context, ignoring.'.format(output_type))
                            continue
                        input_device_label = event_data['input_context']['device_label']
                        event_detail = ""
                        if 'event_detail' in event_data['input_context']:
                            event_detail = ' {}'.format(event_data['input_context']['event_detail'])
                        notification_message = '{}{}'.format(input_device_label, event_detail)
                        log.info("TTS '{}'".format(notification_message))
                        self.notifier.send_pyobj(TTSNotification(message=notification_message))
                    elif output_type.lower() == 'camera':
                        log.info("Camera snapshot '{}'".format(trigger_output['device_label']))
                        trigger_output.update({'timestamp': timestamp})
                        self.snapshot.send_pyobj(trigger_output)
                    else:
                        log.error('Unconfigured output type {} for input context {}'.format(output_type, event_data))
                        continue
            except ContextTerminated:
                self.listener.close()
                self.notifier.close()
                self.snapshot.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class FileType(object):

    def __init__(self):
        self.mime = MimeTypes()

    def mime_type(self, file_path):
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None and len(mime_type) > 0:
            return mime_type[0]
        return None

    def test_type(self, file_path, file_type):
        mime_type = self.mime_type(file_path)
        if mime_type is not None and mime_type.startswith('{}/'.format(file_type)):
            # return the specific file type
            return mime_type.split('/')[1]
        return None


filetype = None


class Notification(object, metaclass=ABCMeta):
    def __init__(self, message):
        self.message = message

    def __str__(self):
        return self.message


class TTSNotification(Notification):

    def __init__(self, message):
        super(TTSNotification, self).__init__(message=message)


class AudioNotification(Notification):

    def __init__(self, message):
        super(AudioNotification, self).__init__(message=message)


class Notifier(Thread):

    def __init__(self):
        super(Notifier, self).__init__(name=self.__class__.__name__)
        self.daemon = True
        # audio player wrapper
        self.player = None

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_NOTIFIER)

        self.tts_default_sound_file = config.get('app', 'tts_default_sound')
        with open(config.get('ibm', 'tts_creds')) as config_file:
            tts_api_cfg = json.load(config_file)
        self.tts_file_format = 'flac'
        self.tts_file_encoding = 'audio/{}'.format(self.tts_file_format)
        self.tts_voice = config.get('ibm', 'tts_voice')
        self.tts = text_to_speech = TextToSpeechV1(
            iam_apikey=tts_api_cfg['apikey'],
            url=tts_api_cfg['url']
        )

    def spawn_player(self):
        if self.player:
            try:
                # be kind
                self.player.stdin.write('quit' + os.linesep)
                # be not so kind
                self.player.kill()
            except Exception:
                log.debug('Ignoring failed attempt to kill player.', exc_info=1)
        self.player = Popen(mplayer, stdin=PIPE, stdout=PIPE, universal_newlines=True, bufsize=1)
        # set the O_NONBLOCK flag of stdout file descriptor:
        flags = fcntl(self.player.stdout, F_GETFL)  # get current stdout flags
        fcntl(self.player.stdout, F_SETFL, flags | O_NONBLOCK)

    def run(self):
        try:
            self.spawn_player()
            # get current stdout flags
            mplayer_init_file = 'loadfile {}'.format(os.path.join(TTS_DIR, config.get('app', 'tts_startup_sound')))
            self.player.stdin.write(mplayer_init_file + os.linesep)
        except Exception:
            log.exception(self.__class__.__name__)
            sentry.captureException()
            # nothing can be done to fix this
            raise

        while True:
            notification = None
            try:
                notification = self.socket.recv_pyobj()
                if isinstance(notification, TTSNotification):
                    try:
                        self.say(str(notification))
                    except BrokenPipeError:
                        # attempt to respawn the player
                        self.spawn_player()
                        try:
                            # retry the message
                            self.say(str(notification))
                        except Exception:
                            self.play_file(os.path.join(TTS_DIR, self.tts_default_sound_file))
                            # whether we are able to play the default sound successfully or not, raise as unhandled
                            raise
                elif isinstance(notification, AudioNotification):
                    self.play_file(notification.message)
                else:
                    log.error('Unknown notification type {}'.format(notification.__class__))
            except ContextTerminated:
                self.socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    def stop(self):
        if self.player:
            try:
                self.player.stdin.write('quit' + os.linesep)
            except Exception:
                self.player.kill()

    def play_file(self, sound_file):
        if self.player:
            self.player.stdin.write('loadfile {}'.format(sound_file) + os.linesep)
            # delay for at least 1 second for short tones
            sleep(1)
            while True:
                self.player.stdin.write('get_file_name' + os.linesep)
                sleep(1)
                try:
                    sound_file_playing = read(self.player.stdout.fileno(), 1024)
                except OSError:
                    break
                # request the currently playing file
                if not sound_file_playing or len(sound_file_playing.decode().rstrip()) == 0:
                    break
                ans_prefix = 'ANS_FILENAME='
                sound_file_playing = sound_file_playing.decode()
                if sound_file_playing.startswith(ans_prefix):
                    sound_file_playing = sound_file_playing[len(ans_prefix):].rstrip().replace("'", '')
                if sound_file_playing == os.path.basename(sound_file):
                    log.debug('Playing {}.'.format(sound_file_playing))
                else:
                    log.debug('Expected to be playing {} but instead {}. Waiting...'.format(
                        os.path.basename(sound_file),
                        sound_file_playing))
        else:
            log.error("No player loaded to play '{}'".format(sound_file))

    def say(self, message):
        msg_checksum = Notifier.checksum(message)
        log.debug("Checksum for '{}' is [{}]".format(message, msg_checksum))
        tts_file = '{}.{}.{}'.format(msg_checksum, self.tts_voice, self.tts_file_format)
        tts_path = os.path.join(TTS_DIR, tts_file)
        if os.path.isfile(tts_path) and os.path.getsize(tts_path) == 0:
            log.warning('Removing empty file {}'.format(tts_path))
            os.remove(tts_path)
        if filetype.test_type(tts_path, 'audio') is None:
            log.warning('Removing audio file of unknown type {}'.format(tts_path))
            os.remove(tts_path)
        log.debug('{} exists? {}'.format(tts_path, os.path.isfile(tts_path)))
        if not os.path.isfile(tts_path):
            log.debug("Generating '{}' using voice {} in format {}".format(message, self.tts_voice, self.tts_file_encoding))
            r = self.tts.synthesize(
                text=message,
                accept=self.tts_file_encoding,
                voice=self.tts_voice)
            # only write a file upon success
            with open(tts_path, 'wb') as fd:
                for chunk in r.response.iter_content(1024*64):
                    fd.write(chunk)
            log.debug('Written {} bytes to {}'.format(os.path.getsize(tts_path), tts_path))
        if os.path.isfile(tts_path):
            # now play
            log.debug("Saying '{}'...".format(message))
            self.play_file(tts_path)
        else:
            raise Exception('No file {} to play "{}"'.format(tts_path, message))

    @staticmethod
    def checksum(message):
        m = hashlib.md5()
        m.update(message.encode())
        return m.hexdigest()


class Snapshot(Thread):

    def __init__(self, camera_profiles, cloud_storage_url):
        super(Snapshot, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.cameras = camera_profiles
        self.default_command = config.get('camera', 'default_command')
        self.default_image_format = config.get('camera', 'default_image_format')

        self.cloud_storage_url = cloud_storage_url

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_SNAPSHOT)

        self.uploader = zmq_context.socket(zmq.PUSH)
        self.uploader.connect(URL_WORKER_UPLOADER)

    def run(self):
        while True:
            try:
                output_trigger = self.socket.recv_pyobj()
                timestamp = output_trigger['timestamp']
                device_key = output_trigger['device_key']
                device_label = output_trigger['device_label']
                if device_key not in self.cameras:
                    log.error("Camera configuration missing for '{}.'".format(device_label))
                    continue
                camera_profile = self.cameras[device_key]
                camera_command = self.default_command
                if 'device_params' in output_trigger:
                    camera_command = output_trigger['device_params']
                # unclear whether cam supports requests auth header
                camera_auth_user, camera_auth_password = camera_profile['auth'].split(':')
                for tries in range(1, 4):
                    try:
                        r = requests.get('http://{}/cgi-bin/CGIProxy.fcgi'.format(camera_profile['url']), params={
                            'cmd': camera_command,
                            'usr': camera_auth_user,
                            'pwd': camera_auth_password,
                        })
                        image_data = r.content
                        im = Image.open(BytesIO(image_data))
                        break
                    except OSError:
                        log.warning("Problem getting image from {}. Retrying...".format(camera_profile['url']),
                                    exc_info=True)
                        sleep(0.1)
                        if tries >= 3:
                            raise
                unix_timestamp = int((timestamp.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds())
                #TODO: fixme
                log.info('DEBUG: basing {} off of {}'.format(unix_timestamp, timestamp))
                output_filename = os.path.join(camera_profile['storage'],
                                               'fetch_' + str(unix_timestamp) + '.' + self.default_image_format)
                self.uploader.send_pyobj((
                    timestamp,
                    {
                        'active_devices': [
                            {
                                'device_key': device_key,
                                'device_label': device_label,
                                'type': 'camera',
                                'image': image_data,
                            }
                        ],
                        'storage_url': self.cloud_storage_url
                    }
                ))
                log.info('{} ({} {} {}) => {}.'.format(device_label, im.format, im.size, im.mode, output_filename))
                # persist for Cloud
                im.save(output_filename)
            except ContextTerminated:
                self.socket.close()
                self.uploader.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class DeviceEvent(object):

    def __init__(self, device_key, device_type, device_location=None):
        self._device_key = device_key
        self._device_type = device_type
        self._device_location = device_location

        self._timestamp = None
        self._event_detail = None

    @property
    def device_key(self):
        return self._device_key

    @property
    def device_type(self):
        return self._device_type

    @property
    def device_location(self):
        return self._device_location

    @property
    def timestamp(self):
        if self._timestamp is None:
            self._timestamp = make_timestamp()
        return self._timestamp

    @timestamp.setter
    def timestamp(self, value):
        self._timestamp = make_timestamp(timestamp=value, as_tz=tz.tzlocal())

    @property
    def timestamp_string(self):
        return self.timestamp.strftime(DATE_FORMAT)

    @property
    def event_detail(self):
        return self._event_detail

    @event_detail.setter
    def event_detail(self, value):
        self._event_detail = value

    @property
    def dict(self):
        representation = {
            'device_key': self._device_key,
            'device_type': self._device_type,
            'timestamp': self.timestamp_string
        }
        if self._device_location:
            representation.update({
                'device_location': self._device_location
            })
        if self._event_detail:
            representation.update({
                'event_detail': self._event_detail
            })
        return representation

    def __str__(self):
        return self._device_key


class CloudStorage(object, metaclass=ABCMeta):
    @abstractmethod
    def cloud_storage_url(self):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        # set by the thread
        self._gdrive_folder_id = None
        self._gdrive_folder_url = None

    @property
    def cloud_storage_folder_id(self):
        return self._gdrive_folder_id

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug('Google credentials not found in [{}]. Interactive setup may follow.'.format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug('Saved Google credentials to {}'.format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError('Unexpected result listing Google Drive for {}: {}'.format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link


class GoogleDriveArchiver(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder, gdrive_folder_id, gdrive_folder_url):
        super(GoogleDriveArchiver, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = dict()

        self._gdrive_folder_id = gdrive_folder_id
        self._gdrive_folder_url = gdrive_folder_url

    def run(self):
        while True:
            log.debug('Finding files in {} ({}) to archive.'.format(self._gdrive_folder, self._gdrive_folder_id))
            try:
                file_list = self._archive_drive.ListFile({
                    'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                        self._gdrive_folder_id
                    ),
                    'maxResults': 100,
                })
                archived = 0
                try:
                    while True:
                        page = file_list.GetList()
                        log.info('Inspecting {} files for archival...'.format(len(page)))
                        for file1 in page:
                            if self.archive(gdrive=self._archive_drive,
                                            gdrive_file=file1,
                                            root_folder_id=self._gdrive_folder_id):
                                archived += 1
                except StopIteration:
                    log.info('Archived {} image snapshots.'.format(archived))
            except (ApiRequestError, FileNotUploadedError, socket_error, HttpError):
                log.exception('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            sleep(60*60*24)

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, url = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, url = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, url = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = list()
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False


class GoogleDriveUploader(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveUploader, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_CLOUD_STORAGE)

        # determine the Drive folder details synchronously
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, self._gdrive_folder)

    def run(self):
        while True:
            try:
                (snapshot_path, snapshot_timestamp) = self.socket.recv_pyobj()
                if os.path.exists(snapshot_path):
                    self.upload(file_path=snapshot_path, created_time=snapshot_timestamp)
            except ContextTerminated:
                self.socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = filetype.mime_type(file_path)
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            for i in range(0, 3):
                try:
                    f.Upload()
                except (ApiRequestError, BadStatusLine, SSLEOFError, BrokenPipeError):
                    if i >= 3:
                        raise
                    else:
                        log.warning("Problem uploading '{}' to Google Drive. Retrying...".format(file_path), exc_info=True)
                        sleep(1)
                        continue
                break
            link_msg = ""
            if 'thumbnailLink'in f:
                link = f['thumbnailLink']
                # specify our own thumbnail size
                if '=' in link:
                    link = link.rsplit('=')[0]
                    link += '=s1024'
                link_msg = " Thumbnail at {}".format(link)
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}').{}".format(
                    os.path.basename(file_path), self._gdrive_folder, f['id'], link_msg))
        except FileNotUploadedError:
            log.exception('Cannot upload {} to Google Drive'.format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, fs_observer):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self.device_events = dict()

        fs_observer.schedule(self, snapshot_root, recursive=True)

        self.cloud_storage_socket = zmq_context.socket(zmq.PUSH)
        self.cloud_storage_socket.connect(URL_WORKER_CLOUD_STORAGE)

        self.uploader = zmq_context.socket(zmq.PUSH)
        self.uploader.connect(URL_WORKER_UPLOADER)

        self._cloud_storage_url = None

    @property
    def cloud_storage_url(self):
        return self._cloud_storage_url

    @cloud_storage_url.setter
    def cloud_storage_url(self, cloud_storage_url):
        self._cloud_storage_url = cloud_storage_url

    def close(self):
        self.cloud_storage_socket.close()
        self.uploader.close()

    def add_image_dir(self, device_key, device_type, device_location, image_dir):
        if image_dir in self.device_events:
            raise RuntimeError('Image source label {} is already configured.'.format(device_location))
        # create pre-canned device events for reuse later
        self.device_events[image_dir] = DeviceEvent(
            device_key=device_key,
            device_type=device_type,
            device_location=device_location
        )

    def _get_device_event(self, event_directory):
        for image_dir, device_event in list(self.device_events.items()):
            if image_dir in event_directory:
                return copy.copy(device_event)
        return None

    @property
    def watched_dirs(self):
        return list(self.device_events.keys())

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # remove empty files
            if os.path.isfile(snapshot_path) and os.path.getsize(snapshot_path) == 0:
                log.warning('Removing empty file {}'.format(snapshot_path))
                os.remove(snapshot_path)
                return
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(snapshot_root):
                # noinspection PyBroadException
                try:
                    # image snapshot that can be mapped to a device?
                    device_event = self._get_device_event(snapshot_path)
                    if device_event:
                        log.info('{} from {}'.format(device_event, snapshot_path))
                        file_base_name = os.path.splitext(os.path.basename(snapshot_path))[0]
                        if '_' in file_base_name:
                            date_string = file_base_name.split('_')[1]
                        else:
                            date_string = file_base_name
                        #TODO: fixme
                        log.info('DEBUG: setting device event timestamp to {}'.format(date_string))
                        device_event.timestamp = date_string
                        # TODO: fixme
                        log.info('DEBUG: device event timestamp is now {}'.format(device_event.timestamp))
                        try:
                            # do not notify for fetched image data
                            if 'fetch' not in snapshot_path:
                                self.uploader.send_pyobj((
                                    device_event.timestamp,
                                    {
                                        'active_devices': [device_event.dict],
                                        'storage_url': self._cloud_storage_url
                                    }
                                ))
                            # upload the image snapshot to Cloud
                            self.cloud_storage_socket.send_pyobj((
                                snapshot_path,
                                device_event.timestamp
                            ))
                        except ContextTerminated:
                            self.uploader.close()
                            self.cloud_storage_socket.close()
                            return
                    else:
                        log.warning("Ignored unmapped path event: {}".format(snapshot_path))
                except Exception:
                    log.exception('Cannot process {}'.format(snapshot_path))
                    sentry.captureException()
                    sleep(1)


class SignalHandler:

    def __init__(self):
        self.last_signal = 0
        signal.signal(signal.SIGTERM, self.terminate)
        signal.signal(signal.SIGHUP, self.hup)

    def hup(self, signum, frame):
        log.warning('Signal {} received.'.format(signum))
        self.last_signal = signum
        if log.getEffectiveLevel() == logging.INFO:
            log.setLevel(logging.DEBUG)
        elif log.getEffectiveLevel() == logging.DEBUG:
            log.setLevel(logging.INFO)

    def terminate(self, signum, frame):
        log.warning('Signal {} received.'.format(signum))
        self.last_signal = signum
        raise RuntimeWarning()


def thread_nanny(threads_tracked, signal_handler):
    while True:
        # kill the nanny now
        if signal_handler.last_signal == signal.SIGTERM:
            break
        threads_alive = set()
        for thread_info in threading.enumerate():
            if thread_info.isAlive():
                threads_alive.add(thread_info.getName())
        if len(threads_tracked - threads_alive) > 0:
            message = 'A thread has died. Expected threads are [{}], missing is [{}].'.format(threads_tracked, threads_tracked - threads_alive)
            log.error(message)
        time.sleep(10)


if __name__ == "__main__":
    # DEBUG logging until startup complete
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    if sys.stdout.isatty():
        log.warning("Using console logging because there is a tty.")
        stream_handler = logging.StreamHandler(stream=sys.stdout)
        stream_handler.setFormatter(formatter)
        log.addHandler(stream_handler)
    # file system listener
    observer = Observer()
    observer.name = observer.__class__.__name__
    upload_event_handler = UploadEventHandler(fs_observer=observer)
    # construct the device representation
    input_types = dict(config.items('input_type'))
    input_locations = dict(config.items('input_location'))
    output_types = dict(config.items('output_type'))
    output_locations = dict(config.items('output_location'))
    camera_urls = dict(config.items('camera_url'))
    camera_auths = dict(config.items('camera_auth'))
    device_info = dict()
    device_info['inputs'] = list()
    for field, input_type in list(input_types.items()):
        input_location = input_locations[field]
        device_key = '{} {}'.format(input_locations[field], input_type)
        device_info['inputs'].append({
            'type': input_type,
            'location': input_location,
            'device_key': device_key
        })
        if input_type.lower() == 'camera':
            upload_event_handler.add_image_dir(
                device_key=device_key,
                device_type=input_type,
                device_location=input_location,
                image_dir=os.path.join(config.get('snapshots', 'upload_dir'), input_location.lower()))
    device_info['outputs'] = list()
    camera_profiles = {}
    for field, output_type in list(output_types.items()):
        output_device = {}
        if field in output_locations:
            output_location = output_locations[field]
            device_key = '{} {}'.format(output_location, output_type)
            output_device['location'] = output_location
        else:
            device_key = output_type
        output_device.update({
            'type': output_type,
            'device_key': device_key
        })
        device_info['outputs'].append(output_device)
        if output_type.lower() == 'camera':
            # now build the profile for internal use
            camera_profile = output_device.copy()
            camera_profile.update({
                'url': camera_urls[field],
                'auth': camera_auths[field],
                'storage': os.path.join(snapshot_root, config.get('snapshots', 'upload_dir'), output_location.lower())
            })
            camera_profiles[device_key] = camera_profile
    log.info('Monitoring directories in {} for changes: {}'.format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # threads that we want to ensure are alive
    threads_tracked = set()
    uploader = Uploader()
    uploader.start()
    threads_tracked.add(uploader.getName())
    # top-level types
    filetype = FileType()
    # application threads
    notifier = Notifier()

    # ensure that auth is properly set up first
    google_drive_uploader = GoogleDriveUploader(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'))
    google_drive_archiver = GoogleDriveArchiver(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'),
        gdrive_folder_id=google_drive_uploader.cloud_storage_folder_id,
        gdrive_folder_url=google_drive_uploader.cloud_storage_url)
    # tell the uploader about the Cloud storage URL
    upload_event_handler.cloud_storage_url = google_drive_uploader.cloud_storage_url
    snapshotter = Snapshot(camera_profiles=camera_profiles, cloud_storage_url=google_drive_uploader.cloud_storage_url)
    # start threads
    notifier.start()
    threads_tracked.add(notifier.getName())
    snapshotter.start()
    threads_tracked.add(snapshotter.getName())
    # start the collectors
    observer.start()
    threads_tracked.add(observer.getName())
    # finish with the device activator
    device_activator = DeviceActivator()
    device_activator.start()
    threads_tracked.add(device_activator.getName())
    # app plumbing
    signal_handler = SignalHandler()
    f = threading.Thread(name='nanny', target=thread_nanny, args=(threads_tracked, signal_handler,))
    f.setDaemon(True)
    f.start()
    uploader_socket = zmq_context.socket(zmq.PUSH)
    uploader_socket.connect(URL_WORKER_UPLOADER)
    try:
        # startup completed
        # back to INFO logging
        log.setLevel(logging.INFO)
        # start Google Drive uploader
        google_drive_uploader.start()
        threads_tracked.add(google_drive_uploader.getName())
        # start the Google Driver archiver last
        google_drive_archiver.start()
        threads_tracked.add(google_drive_archiver.getName())
        while True:
            uploader_socket.send_pyobj((
                None,  # timestamp
                {
                    #TODO statistics
                    'device_info': device_info
                }
            ))
            time.sleep(HEARTBEAT_INTERVAL_SECONDS)
    except(KeyboardInterrupt, RuntimeWarning, ContextTerminated):
        notifier.stop()
        observer.stop()
        observer.join()
        upload_event_handler.close()
        # since this thread and the signal handler are one and the same
        uploader_socket.close()
        zmq_context.term()
    finally:
        log.info('Removing PID file {}'.format(pidfile))
        os.unlink(pidfile)
