#!/usr/bin/env python
import dateutil.parser
import logging
import logging.handlers

import copy
import face_recognition
import netifaces
import os
import pytz
import requests
import signal
import sys
import threading
import time
import umsgpack
import zmq

from configparser import ConfigParser

from abc import abstractmethod, ABCMeta
from datetime import datetime, timedelta
from dateutil import tz
from face_recognition import face_locations, load_image_file
from http.client import BadStatusLine
from io import BytesIO
from mimetypes import MimeTypes
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError, ApiRequestError
from googleapiclient.errors import HttpError
from raven import Client as Sentry
from requests.adapters import ConnectionError
from requests.exceptions import RequestException
from socket import error as socket_error
from ssl import SSLEOFError
from threading import Thread
from time import sleep
from traceback import StackSummary
from urllib.request import pathname2url
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer

from zmq import ContextTerminated
from zmq.error import ZMQError

from PIL import Image

import botocore
import os.path
from botoflow import activity, \
    activities, \
    execute, \
    return_, \
    workflow_starter, \
    WorkflowDefinition, \
    ThreadedWorkflowExecutor, \
    ThreadedActivityExecutor
from botoflow.workers.workflow_worker import WorkflowWorker
from botoflow.workers.activity_worker import ActivityWorker
from botoflow.constants import MINUTES
from botoflow.exceptions import ActivityTaskFailedError, \
    WorkflowFailedError, WorkflowTimedOutError


APP = os.path.basename(__file__)
if sys.stdout.isatty() and os.system('systemctl status app') == 0:
    print("{} is already running. Use 'systemctl stop app' to stop first.".format(APP))
    sys.exit(1)

# set the working directory for libraries that assume this (such as PyDrive)
DIR = os.path.abspath(os.path.dirname(__file__))
os.chdir(DIR)
log = logging.getLogger(APP)
# do not propagate to console logging
log.propagate = False

config = ConfigParser()
config.optionxform = str
config.read([os.path.join(DIR, '{}.conf'.format(APP))])

snapshot_root = config.get('snapshots', 'root_dir')

cloud_storage = None

zmq_context = zmq.Context()
zmq_context.setsockopt(zmq.LINGER, 0)
shutting_down = False

URL_WORKER_SNAPSHOT = 'inproc://snapshot'
URL_WORKER_UPLOADER = 'inproc://uploader'
URL_WORKER_FACE_DETECTOR = 'inproc://face-detector'
URL_WORKER_CLOUD_STORAGE = 'inproc://cloud-storage'
DATE_FORMAT = '%Y-%m-%dT%H:%M:%S.%f%z'

HEARTBEAT_INTERVAL_SECONDS = 5

sentry = Sentry()

# lifted from the defunct https://github.com/baudm/mplayer.py/blob/master/mplayer/core.py
mplayer = ['mplayer',
           '-slave',
           '-idle',
           '-really-quiet',
           '-nolirc',
           '-msglevel', 'global=4',
           '-input', 'nodefault-bindings',
           '-noconfig', 'all']


def make_timestamp(timestamp=None, as_tz=pytz.utc, make_string=False):
    if timestamp is None:
        timestamp = datetime.utcnow().replace(tzinfo=pytz.utc)
    elif isinstance(timestamp, float) or isinstance(timestamp, int):
        timestamp = datetime.utcfromtimestamp(timestamp).replace(tzinfo=pytz.utc)
    elif isinstance(timestamp, str):
        try:
            timestamp = dateutil.parser.parse(timestamp)
            log.debug('Parsed timestamp is {}'.format(timestamp))
        except ValueError:
            try:
                timestamp = datetime.utcfromtimestamp(int(timestamp)).replace(tzinfo=pytz.utc)
                log.debug('Parsed integer timestamp is {}'.format(timestamp))
            except ValueError:
                raise RuntimeError("Unknown date/time type: '{}'".format(timestamp))
    if timestamp.tzinfo is None:
        local_tz = tz.tzlocal()
        #TODO: fixme
        log.info('{}: fixed to local time {}'.format(timestamp, local_tz))
        # we use the default specific to the physical locality of the devices
        timestamp = timestamp.replace(tzinfo=local_tz)
    if timestamp.tzinfo != as_tz:
        # now adjust to requested TZ
        new_timestamp = timestamp.astimezone(tz=as_tz)
        #TODO: fixme
        log.info('{} adjusted to {} ({} to {})'.format(timestamp, new_timestamp, timestamp.tzinfo, as_tz))
        timestamp = new_timestamp
    if make_string:
        return timestamp.strftime(DATE_FORMAT)
    return timestamp


@activities(schedule_to_start_timeout=1*MINUTES,
            start_to_close_timeout=1*MINUTES)
class DeviceInfoActivity(object):

    @activity('1.0')
    def get_ip_address(self):
        return netifaces.gateways()['default'][netifaces.AF_INET][0]


@activities(schedule_to_start_timeout=1*MINUTES,
            start_to_close_timeout=1*MINUTES)
class SnapshotActivity(object):

    def __init__(self, zmq_url):
        self._zmq_url = zmq_url
        self._zmq_worker = None

    @activity('1.0')
    def snapshot_camera(self, device_key, camera_command):
        try:
            # create ZMQ socket and use on the correct thread
            if (self._zmq_worker is None):
                self._zmq_worker = zmq_context.socket(zmq.PUSH)
                self._zmq_worker.connect(self._zmq_url)
            self._zmq_worker.send_pyobj((device_key, camera_command))
        except Exception:
            log.exception(self.__class__.__name__)
            sentry.captureException()
            raise

    def stop(self):
        # create ZMQ socket and use on the correct thread
        if (self._zmq_worker is not None):
            self._zmq_worker.close()


class Uploader(Thread):

    def __init__(self):
        super(Uploader, self).__init__(name=self.__class__.__name__)
        self.daemon = True
        # inproc socket to accept messages to publish
        # to the outside world
        self.inproc_pull = zmq_context.socket(zmq.PULL)
        self.inproc_pull.bind(URL_WORKER_UPLOADER)

    def run(self):
        # Socket to talk to the outside world
        publisher = zmq_context.socket(zmq.PUB)
        try:
            publisher.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                      port=config.get('zmq', 'pubsub_port')))
        except ZMQError:
            log.exception(self.__class__.__name__)
            raise

        while True:
            try:
                (timestamp, event_data) = self.inproc_pull.recv_pyobj()
                publisher.send(Uploader.make_payload(timestamp, event_data))
            except ContextTerminated:
                self.inproc_pull.close()
                publisher.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    @staticmethod
    def make_payload(timestamp=None, data=None):
        send_timestamp = make_timestamp(timestamp=timestamp, make_string=True)
        log.debug('Payload timestamp {}'.format(send_timestamp))
        payload = {'timestamp': send_timestamp}
        if data is not None and len(data) > 0:
            payload['data'] = data
        #TODO: fix me for small payloads
        #log.debug(json.dumps(payload))
        return umsgpack.packb(payload)


class DeviceActivator(Thread):

    def __init__(self):
        super(DeviceActivator, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.listener = zmq_context.socket(zmq.PULL)
        # to create snapshots
        self.snapshot = zmq_context.socket(zmq.PUSH)

    def run(self):
        # outputs
        self.snapshot.connect(URL_WORKER_SNAPSHOT)

        # Socket to talk to the outside world
        try:
            self.listener.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                          port=config.get('zmq', 'pushpull_port')))
        except ZMQError:
            log.exception(self.__class__.__name__)
            raise

        while True:
            try:
                event = umsgpack.unpackb(self.listener.recv())
                if 'timestamp' in event:
                    #TODO: fixme
                    log.info('DEBUG: received timestamp {}'.format(event['timestamp']))
                    timestamp = make_timestamp(timestamp=event['timestamp'], as_tz=tz.tzlocal())
                    # TODO: fixme
                    log.info('DEBUG: transmuted timestamp to {}'.format(timestamp))
                else:
                    timestamp = make_timestamp(as_tz=tz.tzlocal())
                if 'data' not in event:
                    log.warning('Unknown event data: {}'.format(event))
                    continue
                event_data = event['data']
                if 'trigger_output' in event_data:
                    trigger_output = event_data['trigger_output']
                    output_type = trigger_output['type']
                    if output_type.lower() == 'camera':
                        log.info("Camera snapshot '{}'".format(trigger_output['device_label']))
                        trigger_output.update({'timestamp': timestamp})
                        self.snapshot.send_pyobj(trigger_output)
                    else:
                        log.error('Unconfigured output type {} for input context {}'.format(output_type, event_data))
                        continue
            except ContextTerminated:
                self.listener.close()
                self.snapshot.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class FileType(object):

    def __init__(self):
        self.mime = MimeTypes()

    def mime_type(self, file_path):
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None and len(mime_type) > 0:
            return mime_type[0]
        return None

    def test_type(self, file_path, file_type):
        mime_type = self.mime_type(file_path)
        if mime_type is not None and mime_type.startswith('{}/'.format(file_type)):
            # return the specific file type
            return mime_type.split('/')[1]
        return None


filetype = None


class Snapshot(Thread):

    def __init__(self, camera_profiles, cloud_storage_url):
        super(Snapshot, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.cameras = camera_profiles
        self.default_command = config.get('camera', 'default_command')
        self.default_image_format = config.get('camera', 'default_image_format')

        self.cloud_storage_url = cloud_storage_url

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_SNAPSHOT)

        self.uploader = zmq_context.socket(zmq.PUSH)
        self.uploader.connect(URL_WORKER_UPLOADER)

    def run(self):
        while True:
            try:
                output_trigger = self.socket.recv_pyobj()
                timestamp = output_trigger['timestamp']
                device_key = output_trigger['device_key']
                device_label = output_trigger['device_label']
                if device_key not in self.cameras:
                    log.error("Camera configuration missing for '{}.'".format(device_label))
                    continue
                camera_profile = self.cameras[device_key]
                camera_command = self.default_command
                if 'device_params' in output_trigger:
                    camera_command = output_trigger['device_params']
                # unclear whether cam supports requests auth header
                camera_auth_user, camera_auth_password = camera_profile['auth'].split(':')
                for tries in range(1, 4):
                    try:
                        r = requests.get('http://{}/cgi-bin/CGIProxy.fcgi'.format(camera_profile['url']), params={
                            'cmd': camera_command,
                            'usr': camera_auth_user,
                            'pwd': camera_auth_password,
                        })
                        image_data = r.content
                        im = Image.open(BytesIO(image_data))
                        break
                    except (OSError, ConnectionError, RequestException):
                        log.warning("Problem getting image from {}. Retrying...".format(camera_profile['url']),
                                    exc_info=1)
                        sleep(0.1)
                        if tries >= 3:
                            log.exception("Giving up getting image from {} after {} tries.".format(camera_profile['url'],
                                                                                                   tries))
                            continue
                unix_timestamp = int((timestamp.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds())
                #TODO: fixme
                log.info('DEBUG: basing {} off of {}'.format(unix_timestamp, timestamp))
                output_filename = os.path.join(camera_profile['storage'],
                                               'fetch_' + str(unix_timestamp) + '.' + self.default_image_format)
                self.uploader.send_pyobj((
                    timestamp,
                    {
                        'active_devices': [
                            {
                                'device_key': device_key,
                                'device_label': device_label,
                                'type': 'camera',
                                'image': image_data,
                            }
                        ],
                        'storage_url': self.cloud_storage_url
                    }
                ))
                log.info('{} ({} {} {}) => {}.'.format(device_label, im.format, im.size, im.mode, output_filename))
                # persist for Cloud
                im.save(output_filename)
            except ContextTerminated:
                self.socket.close()
                self.uploader.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class FaceDetector(Thread):

    def __init__(self, camera_profiles, cloud_storage_url):
        super(FaceDetector, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.cameras = camera_profiles
        self.default_command = config.get('camera', 'default_command')
        self.default_image_format = config.get('camera', 'default_image_format')

        self.cloud_storage_url = cloud_storage_url

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_SNAPSHOT)

        self.uploader = zmq_context.socket(zmq.PUSH)
        self.uploader.connect(URL_WORKER_UPLOADER)

    def run(self):
        while True:
            try:
                output_trigger = self.socket.recv_pyobj()
                timestamp = output_trigger['timestamp']
                device_key = output_trigger['device_key']
                device_label = output_trigger['device_label']
                if device_key not in self.cameras:
                    log.error("Camera configuration missing for '{}.'".format(device_label))
                    continue
                camera_profile = self.cameras[device_key]
                camera_command = self.default_command
                if 'device_params' in output_trigger:
                    camera_command = output_trigger['device_params']
                # unclear whether cam supports requests auth header
                camera_auth_user, camera_auth_password = camera_profile['auth'].split(':')
                for tries in range(1, 4):
                    try:
                        r = requests.get('http://{}/cgi-bin/CGIProxy.fcgi'.format(camera_profile['url']), params={
                            'cmd': camera_command,
                            'usr': camera_auth_user,
                            'pwd': camera_auth_password,
                        })
                        image_data = r.content
                        im = Image.open(BytesIO(image_data))
                        break
                    except (OSError, ConnectionError, RequestException):
                        log.warning("Problem getting image from {}. Retrying...".format(camera_profile['url']),
                                    exc_info=1)
                        sleep(0.1)
                        if tries >= 3:
                            log.exception("Giving up getting image from {} after {} tries.".format(camera_profile['url'],
                                                                                                   tries))
                            continue
                unix_timestamp = int((timestamp.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds())
                #TODO: fixme
                log.info('DEBUG: basing {} off of {}'.format(unix_timestamp, timestamp))
                output_filename = os.path.join(camera_profile['storage'],
                                               'fetch_' + str(unix_timestamp) + '.' + self.default_image_format)
                self.uploader.send_pyobj((
                    timestamp,
                    {
                        'active_devices': [
                            {
                                'device_key': device_key,
                                'device_label': device_label,
                                'type': 'camera',
                                'image': image_data,
                            }
                        ],
                        'storage_url': self.cloud_storage_url
                    }
                ))
                log.info('{} ({} {} {}) => {}.'.format(device_label, im.format, im.size, im.mode, output_filename))
                # persist for Cloud
                im.save(output_filename)
            except ContextTerminated:
                self.socket.close()
                self.uploader.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class DeviceEvent(object):

    def __init__(self, device_key, device_type, device_location=None):
        self._device_key = device_key
        self._device_type = device_type
        self._device_location = device_location

        self._timestamp = None
        self._event_detail = None

    @property
    def device_key(self):
        return self._device_key

    @property
    def device_type(self):
        return self._device_type

    @property
    def device_location(self):
        return self._device_location

    @property
    def timestamp(self):
        if self._timestamp is None:
            self._timestamp = make_timestamp()
        return self._timestamp

    @timestamp.setter
    def timestamp(self, value):
        self._timestamp = make_timestamp(timestamp=value, as_tz=tz.tzlocal())

    @property
    def timestamp_string(self):
        return self.timestamp.strftime(DATE_FORMAT)

    @property
    def event_detail(self):
        return self._event_detail

    @event_detail.setter
    def event_detail(self, value):
        self._event_detail = value

    @property
    def dict(self):
        representation = {
            'device_key': self._device_key,
            'device_type': self._device_type,
            'timestamp': self.timestamp_string
        }
        if self._device_location:
            representation.update({
                'device_location': self._device_location
            })
        if self._event_detail:
            representation.update({
                'event_detail': self._event_detail
            })
        return representation

    def __str__(self):
        return self._device_key


class CloudStorage(object, metaclass=ABCMeta):
    @abstractmethod
    def cloud_storage_url(self):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        # set by the thread
        self._gdrive_folder_id = None
        self._gdrive_folder_url = None

    @property
    def cloud_storage_folder_id(self):
        return self._gdrive_folder_id

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug('Google credentials not found in [{}]. Interactive setup may follow.'.format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug('Saved Google credentials to {}'.format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError('Unexpected result listing Google Drive for {}: {}'.format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link


class GoogleDriveArchiver(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder, gdrive_folder_id, gdrive_folder_url):
        super(GoogleDriveArchiver, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = dict()

        self._gdrive_folder_id = gdrive_folder_id
        self._gdrive_folder_url = gdrive_folder_url

    def run(self):
        while True:
            log.debug('Finding files in {} ({}) to archive.'.format(self._gdrive_folder, self._gdrive_folder_id))
            try:
                file_list = self._archive_drive.ListFile({
                    'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                        self._gdrive_folder_id
                    ),
                    'maxResults': 100,
                })
                archived = 0
                try:
                    while True:
                        page = file_list.GetList()
                        log.info('Inspecting {} files for archival...'.format(len(page)))
                        for file1 in page:
                            if self.archive(gdrive=self._archive_drive,
                                            gdrive_file=file1,
                                            root_folder_id=self._gdrive_folder_id):
                                archived += 1
                except StopIteration:
                    log.info('Archived {} image snapshots.'.format(archived))
            except (ApiRequestError, FileNotUploadedError, socket_error, HttpError):
                log.exception('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            sleep(60*60*24)

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, url = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, url = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, url = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = list()
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False


class GoogleDriveUploader(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveUploader, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_CLOUD_STORAGE)

        # determine the Drive folder details synchronously
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, self._gdrive_folder)

    def run(self):
        while True:
            try:
                (snapshot_path, snapshot_timestamp) = self.socket.recv_pyobj()
                if os.path.exists(snapshot_path):
                    # FIXME: small delay to ensure that file is complete and
                    # closed before attempting upload
                    if time.time() - os.path.getmtime(snapshot_path) <= 2:
                        sleep(1)
                    self.upload(file_path=snapshot_path, created_time=snapshot_timestamp)
            except ContextTerminated:
                self.socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = filetype.mime_type(file_path)
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            for i in range(0, 3):
                try:
                    f.Upload()
                except (ApiRequestError, BadStatusLine, SSLEOFError, BrokenPipeError):
                    if i >= 3:
                        raise
                    else:
                        log.warning("Problem uploading '{}' to Google Drive. Retrying...".format(file_path), exc_info=1)
                        sleep(1)
                        continue
                break
            link_msg = ""
            if 'thumbnailLink'in f:
                link = f['thumbnailLink']
                # specify our own thumbnail size
                if '=' in link:
                    link = link.rsplit('=')[0]
                    link += '=s1024'
                link_msg = " Thumbnail at {}".format(link)
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}').{}".format(
                    os.path.basename(file_path), self._gdrive_folder, f['id'], link_msg))
        except FileNotUploadedError:
            log.exception('Cannot upload {} to Google Drive'.format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, fs_observer):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self.device_events = dict()

        fs_observer.schedule(self, snapshot_root, recursive=True)

        self.cloud_storage_socket = zmq_context.socket(zmq.PUSH)
        self.cloud_storage_socket.connect(URL_WORKER_CLOUD_STORAGE)

        self.uploader = zmq_context.socket(zmq.PUSH)
        self.uploader.connect(URL_WORKER_UPLOADER)

        self._cloud_storage_url = None

    @property
    def cloud_storage_url(self):
        return self._cloud_storage_url

    @cloud_storage_url.setter
    def cloud_storage_url(self, cloud_storage_url):
        self._cloud_storage_url = cloud_storage_url

    def close(self):
        self.cloud_storage_socket.close()
        self.uploader.close()

    def add_image_dir(self, device_key, device_type, device_location, image_dir):
        if image_dir in self.device_events:
            raise RuntimeError('Image source label {} is already configured.'.format(device_location))
        # create pre-canned device events for reuse later
        self.device_events[image_dir] = DeviceEvent(
            device_key=device_key,
            device_type=device_type,
            device_location=device_location
        )

    def _get_device_event(self, event_directory):
        for image_dir, device_event in list(self.device_events.items()):
            if image_dir in event_directory:
                return copy.copy(device_event)
        return None

    @property
    def watched_dirs(self):
        return list(self.device_events.keys())

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # remove empty files
            if os.path.isfile(snapshot_path) and os.path.getsize(snapshot_path) == 0:
                log.warning('Removing empty file {}'.format(snapshot_path))
                os.remove(snapshot_path)
                return
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(snapshot_root):
                # noinspection PyBroadException
                try:
                    # image snapshot that can be mapped to a device?
                    device_event = self._get_device_event(snapshot_path)
                    if device_event:
                        log.info('{} from {}'.format(device_event, snapshot_path))
                        file_base_name = os.path.splitext(os.path.basename(snapshot_path))[0]
                        if '_' in file_base_name:
                            date_string = file_base_name.split('_')[1]
                        else:
                            date_string = file_base_name
                        #TODO: fixme
                        log.info('DEBUG: setting device event timestamp to {}'.format(date_string))
                        device_event.timestamp = date_string
                        # TODO: fixme
                        log.info('DEBUG: device event timestamp is now {}'.format(device_event.timestamp))
                        try:
                            # do not notify for fetched image data
                            if 'fetch' not in snapshot_path:
                                self.uploader.send_pyobj((
                                    device_event.timestamp,
                                    {
                                        'active_devices': [device_event.dict],
                                        'storage_url': self._cloud_storage_url
                                    }
                                ))
                            # upload the image snapshot to Cloud
                            self.cloud_storage_socket.send_pyobj((
                                snapshot_path,
                                device_event.timestamp
                            ))
                        except ContextTerminated:
                            self.uploader.close()
                            self.cloud_storage_socket.close()
                            return
                    else:
                        log.warning("Ignored unmapped path event: {}".format(snapshot_path))
                except Exception:
                    log.exception('Cannot process {}'.format(snapshot_path))
                    sentry.captureException()
                    sleep(1)


class SignalHandler:

    def __init__(self):
        self.last_signal = 0
        signal.signal(signal.SIGTERM, self.terminate)
        signal.signal(signal.SIGHUP, self.hup)

    def hup(self, signum, frame):
        log.warning('Signal {} received.'.format(signum))
        self.last_signal = signum
        if log.getEffectiveLevel() == logging.INFO:
            log.setLevel(logging.DEBUG)
        elif log.getEffectiveLevel() == logging.DEBUG:
            log.setLevel(logging.INFO)

    def terminate(self, signum, frame):
        log.warning('Signal {} received.'.format(signum))
        self.last_signal = signum
        raise RuntimeWarning()


def thread_nanny(threads_tracked, signal_handler):
    while True:
        # kill the nanny now
        if signal_handler.last_signal == signal.SIGTERM:
            break
        threads_alive = set()
        for thread_info in threading.enumerate():
            if thread_info.isAlive():
                threads_alive.add(thread_info.getName())
        if len(threads_tracked - threads_alive) > 0:
            message = 'A thread has died. Expected threads are [{}], missing is [{}].'.format(threads_tracked, threads_tracked - threads_alive)
            log.fatal(message)
            shutting_down = True
        else:
            sleep(10)


def swf_exception_handler(err: Exception, tb_list: StackSummary):
    log.fatal('SWF processing exception: {} {}'.format(err, tb_list.format()))
    shutting_down = True


if __name__ == "__main__":
    # DEBUG logging until startup complete
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    if sys.stdout.isatty():
        log.warning("Using console logging because there is a tty.")
        stream_handler = logging.StreamHandler(stream=sys.stdout)
        stream_handler.setFormatter(formatter)
        log.addHandler(stream_handler)
    # connect to SWF
    boto_session = botocore.session.Session(profile=config.get('botoflow', 'profile'))
    swf_activity = SnapshotActivity(URL_WORKER_SNAPSHOT)
    swf_worker = ThreadedActivityExecutor(ActivityWorker(boto_session,
                                            config.get('botoflow', 'region'),
                                            config.get('botoflow', 'domain'),
                                            APP,
                                            swf_activity, DeviceInfoActivity()))
    swf_worker._worker.unhandled_exception_handler = swf_exception_handler
    swf_worker.start()
    # file system listener
    observer = Observer()
    observer.name = observer.__class__.__name__
    upload_event_handler = UploadEventHandler(fs_observer=observer)
    # construct the device representation
    input_types = dict(config.items('input_type'))
    input_locations = dict(config.items('input_location'))
    output_types = dict(config.items('output_type'))
    output_locations = dict(config.items('output_location'))
    camera_urls = dict(config.items('camera_url'))
    camera_auths = dict(config.items('camera_auth'))
    device_info = dict()
    device_info['inputs'] = list()
    for field, input_type in list(input_types.items()):
        input_location = input_locations[field]
        device_key = '{} {}'.format(input_locations[field], input_type)
        device_info['inputs'].append({
            'type': input_type,
            'location': input_location,
            'device_key': device_key
        })
        if input_type.lower() == 'camera':
            upload_event_handler.add_image_dir(
                device_key=device_key,
                device_type=input_type,
                device_location=input_location,
                image_dir=os.path.join(
                    config.get('snapshots', 'upload_dir'),
                    input_location.lower().replace(' ', '')))
    device_info['outputs'] = list()
    camera_profiles = {}
    for field, output_type in list(output_types.items()):
        output_device = {}
        if field in output_locations:
            output_location = output_locations[field]
            device_key = '{} {}'.format(output_location, output_type)
            output_device['location'] = output_location
        else:
            device_key = output_type
        output_device.update({
            'type': output_type,
            'device_key': device_key
        })
        device_info['outputs'].append(output_device)
        if output_type.lower() == 'camera':
            # now build the profile for internal use
            camera_profile = output_device.copy()
            camera_profile.update({
                'url': camera_urls[field],
                'auth': camera_auths[field],
                'storage': os.path.join(snapshot_root, config.get('snapshots', 'upload_dir'), output_location.lower())
            })
            camera_profiles[device_key] = camera_profile
    log.info('Monitoring directories in {} for changes: {}'.format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # threads that we want to ensure are alive
    threads_tracked = set()
    uploader = Uploader()
    uploader.start()
    threads_tracked.add(uploader.getName())
    # top-level types
    filetype = FileType()
    # ensure that auth is properly set up first
    try:
        google_drive_uploader = GoogleDriveUploader(
            gauth_creds_file=config.get('gdrive', 'creds_file'),
            gdrive_folder=config.get('gdrive', 'folder'))
        google_drive_archiver = GoogleDriveArchiver(
            gauth_creds_file=config.get('gdrive', 'creds_file'),
            gdrive_folder=config.get('gdrive', 'folder'),
            gdrive_folder_id=google_drive_uploader.cloud_storage_folder_id,
            gdrive_folder_url=google_drive_uploader.cloud_storage_url)
    except Exception:
        log.fatal('Google Drive setup failure.', exc_info=1)
        exit(1)
    # tell the uploader about the Cloud storage URL
    upload_event_handler.cloud_storage_url = google_drive_uploader.cloud_storage_url
    snapshotter = Snapshot(camera_profiles=camera_profiles, cloud_storage_url=google_drive_uploader.cloud_storage_url)
    # start threads
    snapshotter.start()
    threads_tracked.add(snapshotter.getName())
    # start the collectors
    observer.start()
    threads_tracked.add(observer.getName())
    # finish with the device activator
    device_activator = DeviceActivator()
    device_activator.start()
    threads_tracked.add(device_activator.getName())
    # app plumbing
    signal_handler = SignalHandler()
    f = threading.Thread(name='nanny', target=thread_nanny, args=(threads_tracked, signal_handler,))
    f.setDaemon(True)
    f.start()
    uploader_socket = zmq_context.socket(zmq.PUSH)
    uploader_socket.connect(URL_WORKER_UPLOADER)
    try:
        # startup completed
        # back to INFO logging
        log.setLevel(logging.INFO)
        # start Google Drive uploader
        google_drive_uploader.start()
        threads_tracked.add(google_drive_uploader.getName())
        # start the Google Driver archiver last
        google_drive_archiver.start()
        threads_tracked.add(google_drive_archiver.getName())
        while True:
            uploader_socket.send_pyobj((
                None,  # timestamp
                {
                    #TODO statistics
                    'device_info': device_info
                }
            ))
            time.sleep(HEARTBEAT_INTERVAL_SECONDS)
            if shutting_down:
                raise RuntimeWarning("Shutting down...")
    except(KeyboardInterrupt, RuntimeWarning, ContextTerminated) as e:
        message = "Shutting down {}..."
        log.info(message.format('SWF activity worker'))
        swf_worker.stop()
        swf_worker.join()
        log.info(message.format('SWF activity channel'))
        # stop SWF activity to close ZMQ channel
        swf_activity.stop()
        log.info(message.format('Application threads'))
        observer.stop()
        observer.join()
        upload_event_handler.close()
        # since this thread and the signal handler are one and the same
        uploader_socket.close()
        log.info(message.format('ZMQ context'))
        zmq_context.term()
        log.info('Shutdown complete.')