#!/usr/bin/python
import dateutil.parser
import hashlib
import logging
import logging.handlers

import copy
import json
import os
import pytz
import re
import requests
import signal
import sys
import threading
import time
import umsgpack
import zmq

from ConfigParser import ConfigParser

import abc
import gammu.smsd
from clickatell.api import Clickatell
from clickatell.errors import ClickatellError
from clickatell import constants as cc
from datetime import datetime, timedelta
from dateutil import tz
from mimetypes import MimeTypes
from mplayer import Player
from pprint import pprint
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError, ApiRequestError
from pygtail import Pygtail
from sets import Set
from Queue import Queue, Empty
from threading import Thread, Timer
from time import sleep
from umsgpack import UnpackException
from urllib import pathname2url
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer
from zmq import ContextTerminated

# unbuffered STDOUT for print
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)
sys.displayhook = pprint

APP = os.path.basename(__file__)
DIR = os.path.abspath(os.path.dirname(__file__))
# PID file check
pidfile = '/var/run/{}.pid'.format(APP)
if os.path.isfile(pidfile):
    pid = int(open(pidfile, 'r').read())
    message = '{} already exists containing PID.'.format(pidfile, pid)
    proc_path = '/proc/{}/cmdline'.format(pid)
    # existing process?
    if os.path.isfile(proc_path):
        proc_info = open(proc_path, 'r').read()
        if 'python' in proc_info and APP in proc_info:
            print '{} {} is already running.'.format(message, APP)
            sys.exit(1)
    print '{} Removing stale PID file.'.format(message)
    # what's in the PID file is stale, destroy it
    os.unlink(pidfile)
# create a new PID file
file(pidfile, 'w').write(str(os.getpid()))

TTS_DIR = '/data/tts_samples'
# set the working directory for libraries that assume this (such as PyDrive)
os.chdir(DIR)
log = logging.getLogger(APP)
# do not propagate to console logging
log.propagate = False

config = ConfigParser()
config.optionxform = str
config.read([os.path.join(DIR, '{}.conf'.format(APP))])

snapshot_root = config.get('snapshots', 'root_dir')

cloud_storage = None

zmq_context = zmq.Context()
URL_WORKER_NOTIFIER = 'inproc://notifier'
URL_WORKER_UPLOADER = 'inproc://uploader'
URL_WORKER_CLOUD_STORAGE = 'inproc://cloud-storage'
DATE_FORMAT = '%Y-%m-%dT%H:%M:%S.%f%z'

HEARTBEAT_INTERVAL_SECONDS = 5


class Uploader(Thread):

    def __init__(self):
        super(Uploader, self).__init__(name=self.__class__.__name__)
        self.daemon = True
        # inproc socket to accept messages to publish
        # to the outside world
        self.inproc_pull = zmq_context.socket(zmq.PULL)
        self.inproc_pull.bind(URL_WORKER_UPLOADER)

    def run(self):
        # Socket to talk to the outside world
        publisher = zmq_context.socket(zmq.PUB)
        publisher.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                  port=config.get('zmq', 'pubsub_port')))
        while True:
            try:
                event = self.inproc_pull.recv_pyobj()
                timestamp = None
                # drop
                if isinstance(event, DeviceEvent):
                    timestamp = event.timestamp_string
                    event_data = {'active_devices': [event.dict]}
                else:
                    event_data = event
                publisher.send(Uploader.make_payload(timestamp, event_data))
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue

    @staticmethod
    def make_payload(timestamp=None, data=None):
        payload = dict()
        if timestamp is None:
            timestamp = datetime.utcfromtimestamp(time.time()).replace(tzinfo=pytz.utc).strftime(DATE_FORMAT)
        payload['timestamp'] = timestamp
        if data is not None and len(data) > 0:
            payload['data'] = data
        log.debug(json.dumps(payload))
        return umsgpack.packb(payload)


class DeviceActivator(Thread):

    def __init__(self):
        super(DeviceActivator, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.listener = zmq_context.socket(zmq.PULL)
        # what to do with notifications
        self.notifier = zmq_context.socket(zmq.PUSH)

    def run(self):
        # outputs
        self.notifier.connect(URL_WORKER_NOTIFIER)
        # Socket to talk to the outside world
        self.listener.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                      port=config.get('zmq', 'pushpull_port')))
        while True:
            try:
                event = umsgpack.unpackb(self.listener.recv())
                if 'data' not in event:
                    log.warn('Unknown event data: {}'.format(event))
                    continue
                event_data = event['data']
                if 'trigger_output' in event_data:
                    output_type = event_data['trigger_output']['type']
                    if 'input_context' not in event_data:
                        log.warn('{} requested without context, ignoring.'.format(output_type))
                        continue
                    device_label = event_data['input_context']['device_label']
                    event_detail = ""
                    if 'event_detail' in event_data['input_context']:
                        event_detail = '. {}'.format(event_data['input_context']['event_detail'])
                    notification_message = '{}{}'.format(device_label, event_detail)
                    if output_type.lower() == 'tts':
                        log.info("TTS '{}'".format(notification_message))
                        self.notifier.send_pyobj(TTSNotification(message=notification_message))
                    elif output_type.lower() == 'sms':
                        if 'device_params' not in event_data['trigger_output']:
                            log.error('Parameters must be configured for output type {}'.format(output_type))
                            continue
                        recipients = event_data['trigger_output']['device_params'].strip().split(',')
                        for recipient in recipients:
                            name_number = recipient.split(';')
                            log.info("SMS {} ({}) '{}'".format(name_number[0], name_number[1], notification_message))
                            self.notifier.send_pyobj(SMSNotification(
                                message=notification_message,
                                recipient=name_number[1],
                                sender=None,
                                flash=True))
                    else:
                        log.error('Unconfigured output type {} for input context {}'.format(output_type, event_data))
                        continue
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue


class FileType(object):

    def __init__(self):
        self.mime = MimeTypes()

    def mime_type(self, file_path):
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None and len(mime_type) > 0:
            return mime_type[0]
        return None

    def test_type(self, file_path, file_type):
        mime_type = self.mime_type(file_path)
        if mime_type is not None and mime_type.startswith('{}/'.format(file_type)):
            # return the specific file type
            return mime_type.split('/')[1]
        return None


filetype = None


class Notification(object):
    __metaclass__ = abc.ABCMeta

    def __init__(self, message):
        self.message = message

    def __str__(self):
        return self.message


class TTSNotification(Notification):

    def __init__(self, message):
        super(TTSNotification, self).__init__(message=message)


class SMSNotification(Notification):

    def __init__(self, message, recipient, sender=None, flash=False):
        super(SMSNotification, self).__init__(message=message)
        self.recipient = recipient
        self.sender = sender
        self.flash = flash


class AudioNotification(Notification):

    def __init__(self, message):
        super(AudioNotification, self).__init__(message=message)


class Notifier(Thread):

    def __init__(self, sms_provider):
        super(Notifier, self).__init__(name=self.__class__.__name__)
        self.daemon = True
        # audio player wrapper
        self.player = None
        # SMS notification provider
        self.sms_provider = sms_provider

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_NOTIFIER)

        self.tts_default_sound_file = config.get('app', 'tts_default_sound')
        with open(config.get('ibm', 'tts_creds')) as config_file:
            tts_api_cfg = json.load(config_file)
        self.tts_file_format = 'flac'
        self.tts_file_encoding = 'audio/{}'.format(self.tts_file_format)
        self.tts_voice = config.get('ibm', 'tts_voice')
        self.tts_url = '/'.join([tts_api_cfg['credentials']['url'], 'v1/synthesize'])
        self.tts_auth = (tts_api_cfg['credentials']['username'],
                         tts_api_cfg['credentials']['password'])

    def run(self):
        # black-holing STDOUT causes properties to not work
        self.player = Player(stderr=open('/dev/null', 'w'), autospawn=True)
        self.play_file(os.path.join(TTS_DIR, config.get('app', 'tts_startup_sound')))
        while True:
            notification = None
            try:
                notification = self.socket.recv_pyobj()
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue
            if isinstance(notification, TTSNotification):
                try:
                    self.say(str(notification))
                except StandardError:
                    log.exception("Unable to say message: '{}'".format(notification))
                    self.play_file(os.path.join(TTS_DIR, self.tts_default_sound_file))
            elif isinstance(notification, SMSNotification):
                self.send_sms(recipient=notification.recipient,
                              message=notification.message,
                              flash=notification.flash)
            elif isinstance(notification, AudioNotification):
                self.play_file(notification.message)
            else:
                log.error('Unknown notification type {}'.format(notification.__class__))

    def stop(self):
        if self.player:
            self.player.quit()

    def play_file(self, sound_file):
        if self.player:
            self.player.loadfile(sound_file)
            try:
                delay = int(self.player.length)
                # block for the duration of this audio sample
                log.debug("Playing '{}' for {}s".format(sound_file, delay))
                sleep(delay)
            except TypeError:
                log.warn("Playing '{}' without block because no player length was provided.".format(sound_file))
                pass
        else:
            log.error("No player loaded to play '{}'".format(sound_file))

    def say(self, message):
        msg_checksum = Notifier.checksum(message)
        log.debug("Checksum for '{}' is [{}]".format(message, msg_checksum))
        tts_file = '{}.{}.{}'.format(msg_checksum, self.tts_voice, self.tts_file_format)
        tts_path = os.path.join(TTS_DIR, tts_file)
        if os.path.isfile(tts_path) and os.path.getsize(tts_path) == 0:
            log.debug('Removing empty file {}'.format(tts_path))
            os.remove(tts_path)
        if filetype.test_type(tts_path, 'audio') is None:
            log.debug('Removing audio file of unknown type {}'.format(tts_path))
            os.remove(tts_path)
        log.debug('{} exists? {}'.format(tts_path, os.path.isfile(tts_path)))
        if not os.path.isfile(tts_path):
            log.debug("Generating '{}' using {}".format(message, self.tts_url))
            r = requests.get(
                url=self.tts_url,
                auth=self.tts_auth,
                params={'text': message,
                        'voice': self.tts_voice},
                headers={'accept': self.tts_file_encoding},
                allow_redirects=False)
            log.debug('HTTP {} from {}'.format(r.status_code, r.url))
            r.raise_for_status()
            log.debug('HTTP response: {}'.format(r.headers))
            # HTTP30x
            if r.status_code >= 300 and r.status_code < 400:
                # try to give some helpful information
                if 'location' in r.headers:
                    log.warning('You must visit {} to create {}'.format(r.headers['location'], tts_path))
            if r.status_code == requests.codes.ok:
                # only write a file upon success
                with open(tts_path, 'wb') as fd:
                    for chunk in r.iter_content(1024*64):
                        fd.write(chunk)
                log.debug('Written {} bytes to {}'.format(os.path.getsize(tts_path), tts_path))
        if os.path.isfile(tts_path):
            # now play
            log.debug("Saying '{}'...".format(message))
            self.play_file(tts_path)
        else:
            raise StandardError('No file {} to play "{}"'.format(tts_path, message))

    def send_sms(self, recipient, message, flash=False):
        self.sms_provider.send_sms(recipient=recipient, message=message, flash=flash)

    @staticmethod
    def checksum(message):
        m = hashlib.md5()
        m.update(message)
        return m.hexdigest()


class DeviceEvent(object):

    def __init__(self, device_key, device_type, device_location=None):
        self._device_key = device_key
        self._device_type = device_type
        self._device_location = device_location

        self._timestamp = None
        self._event_detail = None

    @property
    def device_key(self):
        return self._device_key

    @property
    def device_type(self):
        return self._device_type

    @property
    def device_location(self):
        return self._device_location

    @property
    def timestamp(self):
        if self._timestamp is None:
            self._timestamp = datetime.utcnow().replace(tzinfo=pytz.utc)
        return self._timestamp

    @timestamp.setter
    def timestamp(self, value):
        if isinstance(value, basestring):
            try:
                self._timestamp = dateutil.parser.parse(value)
                log.debug('Parsed timestamp is {}'.format(self._timestamp))
            except ValueError:
                log.exception("Cannot parse date-like string {}. Defaulting to '{}'.".format(value, self.timestamp))
                return
        elif isinstance(value, datetime):
            self._timestamp = value
        else:
            raise RuntimeError("Unknown date/time type: '{}'".format(value))
        # ensure that some timezone information is present
        if self._timestamp.tzinfo is None:
            use_tz = tz.tzlocal()
            log.debug('{}: setting to local time {}'.format(self._timestamp, use_tz))
            # we use the default specific to the physical locality of the devices
            self._timestamp = self._timestamp.replace(tzinfo=use_tz)
        # now normalize to UTC
        log.debug('{}: setting to UTC from {}'.format(self._timestamp, self._timestamp.tzinfo))
        self._timestamp = self._timestamp.astimezone(pytz.utc)

    @property
    def timestamp_string(self):
        return self.timestamp.strftime(DATE_FORMAT)

    @property
    def event_detail(self):
        return self._event_detail

    @event_detail.setter
    def event_detail(self, value):
        self._event_detail = value

    @property
    def dict(self):
        representation = {
            'device_key': self._device_key,
            'device_type': self._device_type,
            'timestamp': self.timestamp_string
        }
        if self._device_location:
            representation.update({
                'device_location': self._device_location
            })
        if self._event_detail:
            representation.update({
                'event_detail': self._event_detail
            })
        return representation

    def __str__(self):
        return self._device_key


class CloudStorage(object):
    __metaclass__ = abc.ABCMeta

    @abc.abstractproperty
    def cloud_storage_url(self):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, gdrive_folder)

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug('Google credentials not found in [{}]. Interactive setup may follow.'.format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug('Saved Google credentials to {}'.format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError('Unexpected result listing Google Drive for {}: {}'.format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link


class GoogleDriveArchiver(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveArchiver, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = dict()

    def run(self):
        while True:
            log.debug('Finding files in {} ({}) to archive.'.format(self._gdrive_folder, self._gdrive_folder_id))
            try:
                file_list = self._archive_drive.ListFile({
                    'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                        self._gdrive_folder_id
                    ),
                    'maxResults': 100,
                })
                archived = 0
                try:
                    while True:
                        page = file_list.GetList()
                        log.info('Inspecting {} files for archival...'.format(len(page)))
                        for file1 in page:
                            if self.archive(gdrive=self._archive_drive,
                                            gdrive_file=file1,
                                            root_folder_id=self._gdrive_folder_id):
                                archived += 1
                except StopIteration:
                    log.info('Archived {} image snapshots.'.format(archived))
            except (ApiRequestError, FileNotUploadedError):
                log.exception('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            sleep(60*60*24)

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, url = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, url = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, url = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = list()
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False


class GoogleDriveUploader(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveUploader, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_CLOUD_STORAGE)

    def run(self):
        while True:
            try:
                (snapshot_path, snapshot_timestamp) = self.socket.recv_pyobj()
                self.upload(file_path=snapshot_path, created_time=snapshot_timestamp)
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = filetype.mime_type(file_path)
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            f.Upload()
            link_msg = ""
            if 'thumbnailLink'in f:
                link = f['thumbnailLink']
                # specify our own thumbnail size
                if '=' in link:
                    link = link.rsplit('=')[0]
                    link += '=s1024'
                link_msg = " Thumbnail at {}".format(link)
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}').{}".format(
                    os.path.basename(file_path), self._gdrive_folder, f['id'], link_msg))
        except FileNotUploadedError:
            log.exception('Cannot upload {} to Google Drive'.format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, fs_observer):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self.device_events = dict()

        fs_observer.schedule(self, snapshot_root, recursive=True)

        self.cloud_storage_socket = zmq_context.socket(zmq.PUSH)
        self.cloud_storage_socket.connect(URL_WORKER_CLOUD_STORAGE)

        self.uploader = zmq_context.socket(zmq.PUSH)
        self.uploader.connect(URL_WORKER_UPLOADER)

    def add_image_dir(self, device_key, device_type, device_location, image_dir):
        if image_dir in self.device_events:
            raise RuntimeError('Image source label {} is already configured.'.format(device_location))
        # create pre-canned device events for reuse later
        self.device_events[image_dir] = DeviceEvent(
            device_key=device_key,
            device_type=device_type,
            device_location=device_location
        )

    def _get_device_event(self, event_directory):
        for image_dir, device_event in self.device_events.items():
            if image_dir in event_directory:
                return copy.copy(device_event)
        return None

    @property
    def watched_dirs(self):
        return self.device_events.keys()

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(snapshot_root):
                # noinspection PyBroadException
                try:
                    # image snapshot that can be mapped to a device?
                    device_event = self._get_device_event(snapshot_path)
                    if device_event:
                        log.info('{} from {}'.format(device_event, snapshot_path))
                        file_base_name = os.path.splitext(os.path.basename(snapshot_path))[0]
                        if '_' in file_base_name:
                            date_string = file_base_name.split('_')[1]
                        else:
                            date_string = file_base_name
                        device_event.timestamp = date_string
                        self.uploader.send_pyobj(device_event)
                        # upload the image snapshot
                        self.cloud_storage_socket.send_pyobj((
                            snapshot_path,
                            device_event.timestamp
                        ))
                    else:
                        log.warn("Ignored unmapped path event: {}".format(snapshot_path))
                except Exception:
                    log.exception('Cannot process {}'.format(snapshot_path))


class LogTailer(Thread):

    def __init__(self, device_key, device_type, device_location, log_label, log_path):
        super(LogTailer, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.device_key = device_key
        self.device_type = device_type
        self.device_location = device_location

        self.log_label = log_label
        self.log_path = log_path

        self.log_dir = os.path.dirname(log_path)
        self.log_file = os.path.basename(log_path)

        if 'syslog' in self.log_file:
            raise RuntimeError('Tailing syslog will result in log feedback.')

        self.uploader = zmq_context.socket(zmq.PUSH)

    def run(self):
        log.info('Tailing log {} as {}'.format(self.log_path, self.log_label))
        self.uploader.connect(URL_WORKER_UPLOADER)
        while True:
            try:
                for line in Pygtail(self.log_path):
                    notification = self.process_line(line)
                    if notification:
                        self.uploader.send_pyobj(notification)
            except Exception:
                log.exception(self.log_path)

    def process_line(self, log_line):
        log.info('{}: {}'.format(self.log_label, log_line))
        return None


class ApcEventTailer(LogTailer):

    def __init__(self, device_key, device_type, device_location, log_label, log_path):
        super(ApcEventTailer, self).__init__(device_key, device_type, device_location, log_label, log_path)

    def process_line(self, log_line):
        # skip this
        if 'startup succeeded' in log_line or 'apcupsd' in log_line:
            return None
        log_fields = log_line.split()
        # extract the date data
        timestamp = ' '.join(log_fields[:3])
        log_entry = ' '.join(log_fields[3:])
        log.debug('{} @ {}: {}'.format(self.log_label, timestamp, log_entry))
        # construct the device event
        device_event = DeviceEvent(
            device_key=self.device_key,
            device_type=self.device_type,
            device_location=self.device_location
        )
        device_event.timestamp = timestamp
        device_event.event_detail = log_entry
        return device_event


class SMSProvider(object):
    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def send_sms(self, recipient, message, flash):
        return NotImplemented


class GammuSMSProvider(Thread, FileSystemEventHandler, SMSProvider):

    def __init__(self, fs_observer):
        super(GammuSMSProvider, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.notifier = zmq_context.socket(zmq.PUSH)

        gammu_cfg_file = config.get('sms', 'gammu-smsdrc')
        self.smsd = gammu.smsd.SMSD(gammu_cfg_file)
        gammu_cfg = ConfigParser()
        gammu_cfg.optionxform = str
        gammu_cfg.read(gammu_cfg_file)

        balance_pattern = config.get('gammu', 'balance_pattern')
        self.balance_pattern = re.compile(balance_pattern)
        sms_balance_pattern = config.get('gammu', 'sms_balance_pattern')
        self.sms_balance_pattern = re.compile(sms_balance_pattern)
        log.debug("Matching SMS balance checks on patterns: '{}', '{}'".format(balance_pattern, sms_balance_pattern))
        self.sms_balance_check_number = config.get('gammu', 'balance_check_number')
        self.sms_balance_check_message = config.get('gammu', 'balance_check_message')
        self.balance_value_alert = float(config.get('gammu', 'balance_value_alert'))
        self.sms_balance_value_alert = int(config.get('gammu', 'sms_balance_value_alert'))

        self.inbox_path = gammu_cfg.get('smsd', 'inboxpath')
        self.error_path = gammu_cfg.get('smsd', 'errorsmspath')

        # register the spool directories
        for dir in self.spool_directories:
            fs_observer.schedule(self, dir)

    @property
    def spool_directories(self):
        return (self.inbox_path, self.error_path)

    def send_sms(self, recipient, message, flash):
        sms_class = 1
        if flash:
            sms_class = 0
        message = {
            'Text': message,
            'SMSC': {'Location': 1},
            'Number': recipient,
            'Class': sms_class
        }
        self.smsd.InjectSMS([message])

    def run(self):
        # inbound notifications
        self.notifier.connect(URL_WORKER_NOTIFIER)
        while True:
            log.info("Dispatching SMS balance enquiry '{}' to {}".format(
                self.sms_balance_check_message,
                self.sms_balance_check_number))
            self.send_sms(recipient=self.sms_balance_check_number, message=self.sms_balance_check_message, flash=False)
            # sleep until later
            sleep(60*60*24)

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(GammuSMSProvider, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            if self.inbox_path in event.src_path:
                log.info('Incoming SMS at {}'.format(event.src_path))
                for line in open(event.src_path):
                    # log the line
                    log.info(line)
                    balance_response = self.balance_pattern.search(line)
                    topup_needed = False
                    notification_message = ''
                    if balance_response:
                        balance_value = float(balance_response.group(0))
                        if balance_value <= self.balance_value_alert:
                            log.warn('Prepaid balance has reached {}. '.format(balance_value))
                            notification_message += "Prepaid balance is running low. "
                            topup_needed = True
                    balance_response = self.sms_balance_pattern.search(line)
                    if balance_response:
                        balance_value = int(balance_response.group(0))
                        if balance_value <= self.sms_balance_value_alert:
                            log.warn('SMS balance has reached {}. '.format(balance_value))
                            notification_message += "SMS balance is running low. "
                            topup_needed = True
                    if topup_needed:
                        notification_message += 'Top-up soon.'
                    if len(notification_message) > 0:
                        self.notifier.send_pyobj(TTSNotification(message=notification_message))
                    else:
                        # something more generic
                        pass
            elif self.error_path in event.src_path:
                log.warn('SMS error at {}'.format(event.src_path))
                self.notifier.send_pyobj(TTSNotification(message="SMS fault!"))
            else:
                log.warn('Unsupported SMS event path: {}'.format(event.src_path))
                # some other path that is unsupported
                pass


class ClickatellSMSProvider(SMSProvider):

    def __init__(self):
        super(ClickatellSMSProvider, self).__init__()
        user = config.get('clickatell', 'user')
        password = config.get('clickatell', 'password')
        app_id = config.get('clickatell', 'app-id')
        self.clickatell = Clickatell(user, password, app_id)

    def send_sms(self, recipient, message, flash):
        try:
            [resp] = self.clickatell.sendmsg(recipients=[recipient], text=message)
            log.debug('SMS sent: {}'.format(str(resp)))
        except ClickatellError:
            log.exception('Cannot SMS {}: {}'.format(recipient, message))


signal = 0


def signal_handler(signum, frame):
    log.warn('Signal {} received.'.format(signum))
    if signum == signal.SIGHUP:
        if log.getEffectiveLevel() == logging.INFO:
            log.setLevel(logging.DEBUG)
        elif log.getEffectiveLevel() == logging.DEBUG:
            log.setLevel(logging.INFO)
    elif signum == signal.SIGTERM:
        raise SystemExit()


def thread_nanny(threads_tracked):
    while True:
        # kill the nanny now
        if signal == signal.SIGTERM:
            break
        threads_alive = Set()
        for thread_info in threading.enumerate():
            if thread_info.isAlive():
                threads_alive.add(thread_info.getName())
        if len(threads_tracked - threads_alive) > 0:
            message = 'A thread has died. Expected threads are [{}], missing is [{}].'.format(threads_tracked, threads_tracked - threads_alive)
            log.error(message)
            sys.exit(1)
        time.sleep(10)


if __name__ == "__main__":
    # DEBUG logging until startup complete
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    if sys.stdout.isatty():
        log.warn("Using console logging because there is a tty.")
        stream_handler = logging.StreamHandler(stream=sys.stdout)
        stream_handler.setFormatter(formatter)
        log.addHandler(stream_handler)
    # file system listener
    observer = Observer()
    observer.name = observer.__class__.__name__
    upload_event_handler = UploadEventHandler(fs_observer=observer)
    log_tailer = None
    # construct the device representation
    input_types = dict(config.items('input_type'))
    input_locations = dict(config.items('input_location'))
    output_types = dict(config.items('output_type'))
    device_info = dict()
    device_info['inputs'] = list()
    for field, input_type in input_types.items():
        input_location = input_locations[field]
        device_key = '{} {}'.format(input_locations[field], input_type)
        device_info['inputs'].append({
            'type': input_type,
            'location': input_location,
            'device_key': device_key
        })
        if input_type.lower() == 'camera':
            upload_event_handler.add_image_dir(
                device_key=device_key,
                device_type=input_type,
                device_location=input_location,
                image_dir=os.path.join(config.get('snapshots', 'upload_dir'), input_location.lower()))
        elif input_type.lower() == 'ups' and config.has_option('logged_events', 'apcupsd'):
            log_tailer = ApcEventTailer(
                device_key=device_key,
                device_type=input_type,
                device_location=input_location,
                log_label='apcupsd',
                log_path=config.get('logged_events', 'apcupsd'))
    device_info['outputs'] = list()
    for field, output_type in output_types.items():
        device_info['outputs'].append({
            'type': output_type,
            'device_key': output_type
        })
    log.debug('Monitoring directories in {} for changes: {}'.format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # threads that we want to ensure are alive
    threads_tracked = Set()
    uploader = Uploader()
    uploader.start()
    threads_tracked.add(uploader.getName())
    # top-level types
    filetype = FileType()
    # sms
    sms_method = config.get('sms', 'method')
    if sms_method == 'gammu':
        sms_provider = GammuSMSProvider(fs_observer=observer)
        # Since GammuSMSProvider is a Thread
        sms_provider.start()
        threads_tracked.add(sms_provider.getName())
    elif sms_method == 'clickatell':
        sms_provider = ClickatellSMSProvider()
    else:
        raise RuntimeError('Unknown SMS method specified: {}'.format(sms_method))
    # application threads
    notifier = Notifier(sms_provider=sms_provider)
    # ensure that auth is properly set up first
    google_drive_archiver = GoogleDriveArchiver(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'))
    google_drive_uploader = GoogleDriveUploader(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'))
    # start threads
    notifier.start()
    threads_tracked.add(notifier.getName())
    # start the collectors
    google_drive_uploader.start()
    threads_tracked.add(google_drive_uploader.getName())
    observer.start()
    threads_tracked.add(observer.getName())
    if log_tailer:
        log_tailer.start()
        threads_tracked.add(log_tailer.getName())
    # finish with the device activator
    device_activator = DeviceActivator()
    device_activator.start()
    threads_tracked.add(device_activator.getName())
    # start the Google Driver archiver last
    google_drive_archiver.start()
    threads_tracked.add(google_drive_archiver.getName())
    f = threading.Thread(name='nanny', target=thread_nanny, args=(threads_tracked,))
    f.setDaemon(True)
    f.start()
    uploader_socket = zmq_context.socket(zmq.PUSH)
    uploader_socket.connect(URL_WORKER_UPLOADER)
    # set up signal handlers
    signal.signal(signal.SIGHUP, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    try:
        # startup completed
        # back to INFO logging
        log.setLevel(logging.INFO)
        while True:
            uploader_socket.send_pyobj({
                        #TODO statistics
                        'device_info': device_info
                    })
            time.sleep(HEARTBEAT_INTERVAL_SECONDS)
    except(KeyboardInterrupt, SystemExit):
        log.info('Stopping threads...')
        observer.stop()
        observer.join()
        log.info('Closing messaging...')
        zmq_context.term()
    finally:
        log.info('Removing PID file {}'.format(pidfile))
        os.unlink(pidfile)
    log.info('Exiting with code {}'.format(signal))
    # exit using the signal, if any
    sys.exit(signal)
