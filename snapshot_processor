#!/usr/bin/env python
import dateutil.parser
import logging
import logging.handlers

import boto3
import builtins
import copy
# pylint: disable=import-error
import face_recognition
import netifaces
import numpy as np
import os
import pytz
import requests
import rtsp
import sentry_sdk
import signal
import sys
import threading
import time
import umsgpack
import zmq

from configparser import ConfigParser

from abc import abstractmethod, ABCMeta
from datetime import datetime, timedelta
from dateutil import tz
from face_recognition import face_locations, load_image_file
from http.client import BadStatusLine
from io import BytesIO
from mimetypes import MimeTypes
from pathlib import Path
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError, ApiRequestError
from googleapiclient.errors import HttpError
from requests.adapters import ConnectionError
from requests.exceptions import RequestException
from sentry_sdk import capture_exception
from socket import error as socket_error
from ssl import SSLEOFError
from threading import Thread
from time import sleep
from traceback import StackSummary
from urllib.request import pathname2url
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer

from zmq import ContextTerminated
from zmq.error import ZMQError

from PIL import Image

import botocore
import os.path
from botoflow import activity, \
    activities, \
    execute, \
    return_, \
    workflow_starter, \
    WorkflowDefinition, \
    ThreadedWorkflowExecutor, \
    ThreadedActivityExecutor
from botoflow.workers.workflow_worker import WorkflowWorker
from botoflow.workers.activity_worker import ActivityWorker
from botoflow.constants import SECONDS, MINUTES
from botoflow.exceptions import ActivityTaskFailedError, \
    WorkflowFailedError, WorkflowTimedOutError

builtins.APP_NAME = Path(__file__).stem
builtins.SENTRY_EXTRAS = []
import pylib

from pylib.bluetooth import bluetooth_init, ping_bluetooth_devices
from pylib.datetime import is_list, make_timestamp, parse_datetime
from pylib.data import make_payload
from pylib.aws import boto_session, \
    swf_region, \
    swf_domain
from pylib.aws.metrics import post_count_metric
from pylib.aws.swf import SWFActivityWaiter, \
    swf_exception_handler, \
    SnapshotActivity, \
    DeviceInfoActivity, \
    DeviceWorkflow, \
    SnapshotWorkflow
from pylib.process import SignalHandler, exec_cmd
from pylib import threads
from pylib.threads import thread_nanny
from pylib.zmq import Publisher, URL_WORKER_PUBLISHER

# expose builtins for lint-friendly
log = builtins.log
APP_CONFIG = builtins.APP_CONFIG
zmq_context = builtins.zmq_context
APP_NAME = builtins.APP_NAME
DEVICE_NAME = builtins.DEVICE_NAME


URL_WORKER_FACE_DETECTOR = 'inproc://face-detector'
URL_WORKER_CLOUD_STORAGE = 'inproc://cloud-storage'

HEARTBEAT_INTERVAL_SECONDS = 5


def wait_for_file_content(file_path):
    # FIXME: small delay to ensure that file is complete and
    # closed before attempting upload
    if os.path.exists(file_path) and os.path.isfile(file_path):
        sleep_delay = 5
        max_tries = 24
        for tries in range(1, max_tries):
            # no content
            if os.path.getsize(file_path) > 0:
                break
            # less than 5 minutes old
            if time.time() - os.path.getmtime(file_path) > 300:
                break
            log.warning('Waiting for {}s (try {} of {}) on empty file {}'.format(
                sleep_delay,
                tries,
                max_tries,
                file_path))
            sleep(sleep_delay)
            if tries >= max_tries:
                break


def create_snapshot_path(parent_path, operation, unix_timestamp, file_extension):
    return os.path.join(
        parent_path,
        "{}_".format(operation) + str(unix_timestamp) + '.' + file_extension)


class FileType(object):

    def __init__(self):
        self.mime = MimeTypes()

    def mime_type(self, file_path):
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None and len(mime_type) > 0:
            return mime_type[0]
        return None

    def test_type(self, file_path, file_type):
        mime_type = self.mime_type(file_path)
        if mime_type is not None and mime_type.startswith('{}/'.format(file_type)):
            # return the specific file type
            return mime_type.split('/')[1]
        return None


filetype = None


class Snapshot(Thread):

    def __init__(self, camera_profiles, cloud_storage_url):
        super(Snapshot, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.cameras = camera_profiles
        self.default_command = APP_CONFIG.get('camera', 'default_command')
        self.default_image_format = APP_CONFIG.get('camera', 'default_image_format')

        self.cloud_storage_url = cloud_storage_url
        self.socket = zmq_context.socket(zmq.PULL) # pylint: disable=no-member
        self.socket.bind(URL_WORKER_APP) # pylint: disable=undefined-variable

        self.publisher = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member
        self.face_detector_socket = None
        if APP_CONFIG.getboolean('snapshots', 'face_detection_enabled'):
            self.face_detector_socket = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member

    def run(self):
        self.publisher.connect(URL_WORKER_PUBLISHER)
        if self.face_detector_socket:
            self.face_detector_socket.connect(URL_WORKER_FACE_DETECTOR)
        while True:
            try:
                output_trigger = self.socket.recv_pyobj()
                # FIXME: remove block
                if isinstance(output_trigger, dict):
                    timestamp = output_trigger['timestamp']
                    device_key = output_trigger['device_key']
                    device_label = output_trigger['device_label']
                    if 'device_params' in output_trigger:
                        camera_command = output_trigger['device_params']
                else:
                    timestamp = make_timestamp()
                    device_key, device_label = output_trigger
                if device_key not in self.cameras:
                    log.error("Camera configuration missing for '{}.'".format(device_label))
                    post_count_metric('Errors')
                    continue
                camera_profile = self.cameras[device_key]
                camera_command = self.default_command
                # unclear whether cam supports requests auth header
                camera_auth_user, camera_auth_password = camera_profile['auth'].split(':')
                image_data = None
                for tries in range(1, 4):
                    try:
                        r = requests.get('http://{}/cgi-bin/CGIProxy.fcgi'.format(camera_profile['url']), params={
                            'cmd': camera_command,
                            'usr': camera_auth_user,
                            'pwd': camera_auth_password,
                        })
                        image_data = r.content
                        im = Image.open(BytesIO(image_data))
                        break
                    except (OSError, ConnectionError, RequestException) as e:
                        log.warning("Problem getting image from {}. Retrying...".format(camera_profile['url']),
                                    exc_info=1)
                        sleep(0.1)
                        if tries >= 3:
                            log.error("Giving up getting image from {} after {} tries: {}".format(
                                camera_profile['url'],
                                tries,
                                repr(e)))
                            post_count_metric('Errors')
                            break
                unix_timestamp = int((timestamp.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds())
                log.debug('Basing {} off of {}'.format(unix_timestamp, timestamp))
                # publisher data
                publisher_data = {
                    'active_devices': [
                        {
                            'device_key': device_key,
                            'device_label': device_label,
                            'type': 'camera',
                            'image': image_data,
                        }
                    ],
                    'storage_url': self.cloud_storage_url
                }
                if self.face_detector_socket:
                    # send image data for processing
                    self.face_detector_socket.send_pyobj((
                        None,
                        camera_profile['storage'],
                        unix_timestamp,
                        publisher_data
                    ))
                # publish event data
                self.publisher.send_pyobj(publisher_data)
                # create output file path
                output_filename = create_snapshot_path(
                    parent_path=camera_profile['storage'],
                    operation='fetch',
                    unix_timestamp=unix_timestamp,
                    file_extension=self.default_image_format)
                log.info('{} ({} {} {}) => {}.'.format(device_label, im.format, im.size, im.mode, output_filename))
                # persist for Cloud
                im.save(output_filename)
            except ContextTerminated:
                self.socket.close()
                self.publisher.close()
                if self.face_detector_socket:
                    self.face_detector_socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                capture_exception()
                sleep(1)
                continue


class DeviceEvent(object):

    def __init__(self, device_key, device_type, device_location=None):
        self._device_key = device_key
        self._device_type = device_type
        self._device_location = device_location

        self._timestamp = None
        self._event_detail = None

    @property
    def device_key(self):
        return self._device_key

    @property
    def device_type(self):
        return self._device_type

    @property
    def device_location(self):
        return self._device_location

    @property
    def timestamp(self):
        if self._timestamp is None:
            self._timestamp = make_timestamp()
        return self._timestamp

    @timestamp.setter
    def timestamp(self, value):
        self._timestamp = make_timestamp(timestamp=value)

    @property
    def timestamp_string(self):
        return self.timestamp.strftime(ISO_DATE_FORMAT) # pylint: disable=undefined-variable

    @property
    def event_detail(self):
        return self._event_detail

    @event_detail.setter
    def event_detail(self, value):
        self._event_detail = value

    @property
    def dict(self):
        representation = {
            'device_key': self._device_key,
            'device_type': self._device_type,
            'timestamp': self.timestamp_string
        }
        if self._device_location:
            representation.update({
                'device_location': self._device_location
            })
        if self._event_detail:
            representation.update({
                'event_detail': self._event_detail
            })
        return representation

    def __str__(self):
        return self._device_key


class CloudStorage(object, metaclass=ABCMeta):
    @abstractmethod
    def cloud_storage_url(self):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        # set by the thread
        self._gdrive_folder_id = None
        self._gdrive_folder_url = None

    @property
    def cloud_storage_folder_id(self):
        return self._gdrive_folder_id

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug('Google credentials not found in [{}]. Interactive setup may follow.'.format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug('Saved Google credentials to {}'.format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP_NAME), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError('Unexpected result listing Google Drive for {}: {}'.format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link


class GoogleDriveArchiver(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder, gdrive_folder_id, gdrive_folder_url):
        super(GoogleDriveArchiver, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = dict()

        self._gdrive_folder_id = gdrive_folder_id
        self._gdrive_folder_url = gdrive_folder_url

    def run(self):
        while not threads.shutting_down:
            log.debug('Finding files in {} ({}) to archive.'.format(self._gdrive_folder, self._gdrive_folder_id))
            try:
                file_list = self._archive_drive.ListFile({
                    'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                        self._gdrive_folder_id
                    ),
                    'maxResults': 100,
                })
                archived = 0
                try:
                    while True:
                        page = file_list.GetList()
                        log.info('Inspecting {} files for archival...'.format(len(page)))
                        for file1 in page:
                            if self.archive(gdrive=self._archive_drive,
                                            gdrive_file=file1,
                                            root_folder_id=self._gdrive_folder_id):
                                archived += 1
                except StopIteration:
                    log.info('Archived {} image snapshots.'.format(archived))
            except (ApiRequestError, FileNotUploadedError, socket_error, HttpError):
                log.exception('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            threads.interruptable_sleep.wait(60*60*24)

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, _ = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, _ = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, _ = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = list()
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False


class GoogleDriveUploader(GoogleDriveManager):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveUploader, self).__init__(
            gauth_creds_file=gauth_creds_file,
            gdrive_folder=gdrive_folder)
        self.name = self.__class__.__name__
        self.daemon = True

        self.socket = zmq_context.socket(zmq.PULL) # pylint: disable=no-member
        self.socket.bind(URL_WORKER_CLOUD_STORAGE)

        # determine the Drive folder details synchronously
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, self._gdrive_folder)

    def run(self):
        while True:
            try:
                (snapshot_path, snapshot_timestamp) = self.socket.recv_pyobj()
                #FIXME: remove
                wait_for_file_content(snapshot_path)
                self.upload(file_path=snapshot_path, created_time=snapshot_timestamp)
            except ContextTerminated:
                self.socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                capture_exception()
                sleep(1)
                continue

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = filetype.mime_type(file_path)
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            for i in range(0, 3):
                try:
                    f.Upload()
                except (ApiRequestError, BadStatusLine, SSLEOFError, BrokenPipeError):
                    if i >= 3:
                        raise
                    else:
                        log.warning("Problem uploading '{}' to Google Drive. Retrying...".format(file_path), exc_info=1)
                        sleep(1)
                        continue
                break
            link_msg = ""
            if 'thumbnailLink'in f:
                link = f['thumbnailLink']
                # specify our own thumbnail size
                if '=' in link:
                    link = link.rsplit('=')[0]
                    link += '=s1024'
                link_msg = " Thumbnail at {}".format(link)
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}').{}".format(
                    os.path.basename(file_path), self._gdrive_folder, f['id'], link_msg))
        except FileNotUploadedError:
            log.exception('Cannot upload {} to Google Drive'.format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, fs_observer, snapshot_root):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self.device_events = dict()
        self._snapshot_root = snapshot_root

        fs_observer.schedule(self, self._snapshot_root, recursive=True)

        self.cloud_storage_socket = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member
        self.cloud_storage_socket.connect(URL_WORKER_CLOUD_STORAGE)

        self.face_detector_socket = None
        if APP_CONFIG.getboolean('snapshots', 'face_detection_enabled'):
            self.face_detector_socket = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member
            self.face_detector_socket.connect(URL_WORKER_FACE_DETECTOR)

        self.publisher = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member
        self.publisher.connect(URL_WORKER_PUBLISHER)

        self._cloud_storage_url = None

    @property
    def cloud_storage_url(self):
        return self._cloud_storage_url

    @cloud_storage_url.setter
    def cloud_storage_url(self, cloud_storage_url):
        self._cloud_storage_url = cloud_storage_url

    def close(self):
        self.cloud_storage_socket.close()
        self.publisher.close()
        if self.face_detector_socket:
            self.face_detector_socket.close()

    def add_image_dir(self, device_key, device_type, device_location, image_dir):
        if image_dir in self.device_events:
            raise RuntimeError('Image source label {} is already configured.'.format(device_location))
        # create pre-canned device events for reuse later
        self.device_events[image_dir] = DeviceEvent(
            device_key=device_key,
            device_type=device_type,
            device_location=device_location
        )

    def _get_device_event(self, event_directory):
        for image_dir, device_event in list(self.device_events.items()):
            if image_dir in event_directory:
                return copy.copy(device_event)
        return None

    @property
    def watched_dirs(self):
        return list(self.device_events.keys())

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(self._snapshot_root):
                # noinspection PyBroadException
                try:
                    # image snapshot that can be mapped to a device?
                    device_event = self._get_device_event(snapshot_path)
                    if device_event:
                        log.info('{} from {}'.format(device_event, snapshot_path))
                        file_base_name = os.path.splitext(os.path.basename(snapshot_path))[0]
                        if '_' in file_base_name:
                            date_string = ' '.join(file_base_name.split('_')[1:])
                        else:
                            date_string = file_base_name
                        device_event.timestamp = date_string
                        try:
                            # do not notify for fetched image data
                            if 'fetch' not in snapshot_path:
                                self.publisher.send_pyobj({
                                    'active_devices': [device_event.dict],
                                    'storage_url': self._cloud_storage_url
                                })
                                if self.face_detector_socket:
                                    # start processing the image data
                                    if file_base_name.endswith('.jpg') and 'face' not in snapshot_path:
                                        self.face_detector_socket.send_pyobj((
                                            snapshot_path,
                                            # no parent path, extracted from snapshot_path
                                            None,
                                            device_event.timestamp,
                                            # no image data
                                            None
                                        ))
                            # upload the image snapshot to Cloud
                            self.cloud_storage_socket.send_pyobj((
                                snapshot_path,
                                device_event.timestamp
                            ))
                        except ContextTerminated:
                            self.publisher.close()
                            self.cloud_storage_socket.close()
                            if self.face_detector_socket:
                                self.face_detector_socket.close()
                            return
                    else:
                        log.warning("Ignored unmapped path event: {}".format(snapshot_path))
                except Exception:
                    log.exception('Cannot process {}'.format(snapshot_path))
                    capture_exception()
                    sleep(1)


class FaceDetector(Thread):

    def __init__(self):
        super(FaceDetector, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.socket = zmq_context.socket(zmq.PULL) # pylint: disable=no-member
        self.socket.bind(URL_WORKER_FACE_DETECTOR)

        self.publisher = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member

    def run(self):
        self.publisher.connect(URL_WORKER_PUBLISHER)
        while True:
            active_device = None
            try:
                (snapshot_path, parent_path, snapshot_timestamp, publisher_data) = self.socket.recv_pyobj()
                if snapshot_path is not None:
                    wait_for_file_content(snapshot_path)
                    (parent_path, snapshot_file) = os.path.split(snapshot_path)
                    # process file data
                    log.info("Loading image data from {}".format(snapshot_file))
                    image = load_image_file(snapshot_path)
                    log.info("Finding faces in image file {}".format(snapshot_path))
                elif publisher_data is not None:
                    active_device = publisher_data['active_devices'][0]
                    log.info("Loading image data from {} event.".format(active_device['device_label']))
                    pil_image = Image.open(BytesIO(active_device['image']))
                    log.info("Finding faces in image {} {} {}...".format(pil_image.format, pil_image.size, pil_image.mode))
                    image = np.array(pil_image)
                else:
                    raise ValueError("No viable image data to use.")
                # find faces using the specified model
                # TODO: make non-CNN model optional for memory-constrained devices
                #faces = face_locations(image)
                faces = face_locations(image, number_of_times_to_upsample=0, model="cnn")
                log.info("{} faces detected.".format(len(faces)))
                face_num = 1
                for face_location in faces:
                    top, right, bottom, left = face_location
                    log.info("Extracting face #{} at Top: {}, Left: {}, Bottom: {}, Right: {}".format(
                        face_num,
                        top,
                        left,
                        bottom,
                        right))
                    # extract sub-image data aligned to face
                    face_image = image[top:bottom, left:right]
                    pil_image = Image.fromarray(face_image)
                    if active_device is not None:
                        image_output = BytesIO()
                        pil_image.save(image_output, format='JPEG')
                        active_device['image'] = image_output.getvalue()
                        self.publisher.send_pyobj(publisher_data)
                    # save the additional image data
                    face_snapshot_path = create_snapshot_path(
                        parent_path=parent_path,
                        operation="face{}".format(face_num),
                        unix_timestamp=snapshot_timestamp,
                        file_extension='jpg')
                    log.info("Saving face #{} to {}".format(face_num, face_snapshot_path))
                    pil_image.save(face_snapshot_path)
                    # next face
                    face_num += 1
            except ContextTerminated:
                self.socket.close()
                self.publisher.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                capture_exception()
                sleep(1)
                continue


class FrameServer(Thread):

    def __init__(self, camera_name, camera_auth, camera_address):
        super(FrameServer, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.detector = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member
        self.capture_duration_seconds = APP_CONFIG.get('camera', 'rtsp_capture_duration_seconds')
        self.rtsp_url = 'rtsp://{}@{}/{}'.format(
            camera_auth,
            camera_address,
            APP_CONFIG.get('camera', 'rtsp_path'))
        self.camera_name = camera_name
        self.camera_address = camera_address

    def process_image(self, image):
        pass

    def run(self):
        self.detector.connect(URL_WORKER_FACE_DETECTOR)
        frame_count = 0
        try:
            with rtsp.Client(rtsp_server_uri=self.rtsp_url) as client:
                image = client.read()
                frame_count += 1
                start_time = time.time()
                while True:
                    self.process_image(image)
                    image = client.read(raw=True)
                    frame_count += 1
                    # stop
                    if time.time() - start_time > self.capture_duration_seconds:
                        break
        except ContextTerminated:
            self.detector.close()
        except Exception:
            log.exception(self.__class__.__name__)
            capture_exception()
            sleep(1)
        log.info('Read {} frames from {}@{} in {}s.'.format(
            frame_count,
            self.camera_name,
            self.camera_address,
            self.capture_duration_seconds))


if __name__ == "__main__":
    # connect to SWF
    swf_activity = SnapshotActivity(URL_WORKER_APP) # pylint: disable=undefined-variable
    swf_worker = ThreadedActivityExecutor(ActivityWorker(boto_session,
                                            swf_region,
                                            swf_domain,
                                            APP_NAME,
                                            swf_activity, DeviceInfoActivity()))
    swf_worker._worker.unhandled_exception_handler = swf_exception_handler
    swf_worker.start()
    # file system listener
    observer = Observer()
    observer.name = observer.__class__.__name__
    snapshot_root = APP_CONFIG.get('snapshots', 'root_dir')
    upload_event_handler = UploadEventHandler(snapshot_root=snapshot_root, fs_observer=observer)
    # construct the device representation
    input_types = dict(APP_CONFIG.items('input_type'))
    input_locations = dict(APP_CONFIG.items('input_location'))
    output_types = dict(APP_CONFIG.items('output_type'))
    output_locations = dict(APP_CONFIG.items('output_location'))
    camera_urls = dict(APP_CONFIG.items('camera_url'))
    camera_auths = dict(APP_CONFIG.items('camera_auth'))
    device_info = dict()
    device_info['inputs'] = list()
    for field, input_type in list(input_types.items()):
        input_location = input_locations[field]
        device_key = '{} {}'.format(input_locations[field], input_type)
        device_info['inputs'].append({
            'type': input_type,
            'location': input_location,
            'device_key': device_key
        })
        if input_type.lower() == 'camera':
            upload_event_handler.add_image_dir(
                device_key=device_key,
                device_type=input_type,
                device_location=input_location,
                image_dir=os.path.join(
                    APP_CONFIG.get('snapshots', 'upload_dir'),
                    input_location.lower().replace(' ', '')))
    device_info['outputs'] = list()
    camera_profiles = {}
    for field, output_type in list(output_types.items()):
        output_device = {}
        if field in output_locations:
            output_location = output_locations[field]
            device_key = '{} {}'.format(output_location, output_type)
            output_device['location'] = output_location
        else:
            device_key = output_type
        output_device.update({
            'type': output_type,
            'device_key': device_key
        })
        device_info['outputs'].append(output_device)
        if output_type.lower() == 'camera':
            # now build the profile for internal use
            camera_profile = output_device.copy()
            camera_profile.update({
                'url': camera_urls[field],
                'auth': camera_auths[field],
                'storage': os.path.join(
                    snapshot_root, 
                    APP_CONFIG.get('snapshots', 'upload_dir'), 
                    output_location.lower().replace(' ', ''))
            })
            camera_profiles[device_key] = camera_profile
    log.info('Monitoring directories in {} for changes: {}'.format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # threads that we want to ensure are alive
    publisher = Publisher(
        zmq_context=zmq_context,
        zmq_ipc_url=URL_WORKER_PUBLISHER,
        pub_ip=APP_CONFIG.get('app', 'eth0_ip'),
        pub_port=APP_CONFIG.get('zmq', 'pubsub_port'))
    publisher.start()
    threads.threads_tracked.add(publisher.getName())
    # face detection
    if APP_CONFIG.getboolean('snapshots', 'face_detection_enabled'):
        face_detector = FaceDetector()
    else:
        face_detector = None
    # top-level types
    filetype = FileType()
    # ensure that auth is properly set up first
    try:
        google_drive_uploader = GoogleDriveUploader(
            gauth_creds_file=APP_CONFIG.get('gdrive', 'creds_file'),
            gdrive_folder=APP_CONFIG.get('gdrive', 'folder'))
        google_drive_archiver = GoogleDriveArchiver(
            gauth_creds_file=APP_CONFIG.get('gdrive', 'creds_file'),
            gdrive_folder=APP_CONFIG.get('gdrive', 'folder'),
            gdrive_folder_id=google_drive_uploader.cloud_storage_folder_id,
            gdrive_folder_url=google_drive_uploader.cloud_storage_url)
    except Exception:
        log.fatal('Google Drive setup failure.', exc_info=1)
        exit(1)
    # tell the uploader about the Cloud storage URL
    upload_event_handler.cloud_storage_url = google_drive_uploader.cloud_storage_url
    snapshotter = Snapshot(camera_profiles=camera_profiles, cloud_storage_url=google_drive_uploader.cloud_storage_url)
    # start threads
    snapshotter.start()
    threads.threads_tracked.add(snapshotter.getName())
    # start the collectors
    observer.start()
    threads.threads_tracked.add(observer.getName())
    # must be main thread
    signal_handler = SignalHandler()
    # start the nanny
    f = threading.Thread(name='nanny', target=thread_nanny, args=(signal_handler,))
    f.setDaemon(True)
    f.start()
    publisher_socket = zmq_context.socket(zmq.PUSH) # pylint: disable=no-member
    publisher_socket.connect(URL_WORKER_PUBLISHER)
    try:
        # startup completed
        # back to INFO logging
        log.setLevel(logging.INFO)
        if face_detector:
            face_detector.start()
            threads.threads_tracked.add(face_detector.getName())
        # start Google Drive uploader
        google_drive_uploader.start()
        threads.threads_tracked.add(google_drive_uploader.getName())
        # start the Google Driver archiver last
        google_drive_archiver.start()
        threads.threads_tracked.add(google_drive_archiver.getName())
        while not threads.shutting_down:
            publisher_socket.send_pyobj({
                #TODO statistics
                'device_info': device_info
            })
            threads.interruptable_sleep.wait(HEARTBEAT_INTERVAL_SECONDS)
        raise RuntimeWarning("Shutting down...")
    except(KeyboardInterrupt, RuntimeWarning, ContextTerminated) as e:
        log.warning(str(e))
        threads.shutting_down = True
        threads.interruptable_sleep.set()
        message = "Shutting down {}..."
        log.info(message.format('SWF activity worker'))
        swf_worker.stop()
        log.info(message.format('SWF activity channel'))
        # stop SWF activity to close ZMQ channel
        swf_activity.stop()
        log.info(message.format('Application threads'))
        observer.stop()
        observer.join()
        upload_event_handler.close()
        # since this thread and the signal handler are one and the same
        publisher_socket.close()
        log.info(message.format('ZMQ context'))
        zmq_context.term()
        log.info(message.format('SWF worker'))
        swf_worker.join()
        log.info('Shutdown complete.')